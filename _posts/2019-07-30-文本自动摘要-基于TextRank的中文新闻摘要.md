---
layout:     post
title:      文本自动摘要：基于TextRank的中文新闻摘要
subtitle:   自动摘要
date:       2019-07-30
author:     DiCaprio
header-img: img/post-bg-nlp.jpg
catalog: true
tags:
    - NLP
---

**目录**

一、基于TextRank的自动摘要原理

- 1、PageRank算法
- 2、TextRank算法

- 3、TextRank做单领域多文本的自动摘要

二、基于TextRank的中文新闻摘要

- 1、整合文档，划分句子
- 2、文本预处理

- 3、加载word2vec词向量

- 4、得到词语的embedding，用WordAVG作为句子的向量表示

- 5、计算句子之间的余弦相似度，构成相似度矩阵

- 6、迭代得到句子的textrank值，排序并取出摘要

---

TextRank 算法源自于 PageRank 算法。PageRank 算法最初是作为互联网网页排序的方法，经过轻微地改动，可以被应用于文本摘要领域。

本文分为两部分，第一部分介绍 TextRank 做文本自动摘要的原理，第二部分介绍用 TextRank 做中文新闻摘要的案例。

# 一、基于TextRank的自动摘要原理

## 1、PageRank算法

首先看 PageRank 的相关概念。PageRank 对于每个网页页面都给出一个正实数，表示网页的重要程度，PageRank 值越高，表示网页越重要，在互联网搜索的排序中越可能被排在前面。假设整个互联网是一个有向图，节点是网页，每条边是转移概率。网页浏览者在每个页面上依照连接出去的超链接，**以等概率跳转到下一个网页**，并且在网页上持续不断地进行这样的随机跳转，这个过程形成了一阶马尔科夫链，比如下图，每个笑脸是一个网页，既有其他网页跳转到该网页，该网页也会跳转到其他网页。在不断地跳转之后，这个马尔科夫链会形成一个平稳分布，而 PageRank 就是这个平稳分布，每个网页的 PageRank 值就是平稳概率。

![https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190518052934981-73030027.png](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTYzMDQ3OC8yMDE5MDUvMTYzMDQ3OC0yMDE5MDUxODA1MjkzNDk4MS03MzAzMDAyNy5wbmc)

PageRank 的核心公式是 PageRank 值的计算公式。这个公式来自于《统计学习方法》，和很多博客上的公式有点轻微的差别，那就是等号右边的平滑项不是（1-d），而是(1-d)/n。

![https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190518060640774-1825595497.png](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTYzMDQ3OC8yMDE5MDUvMTYzMDQ3OC0yMDE5MDUxODA2MDY0MDc3NC0xODI1NTk1NDk3LnBuZw)

加平滑项是因为有些网页没有跳出去的链接，那么转移到其他网页的概率将会是 0，这样就无法保证存在马尔科夫链的平稳分布。于是，我们假设网页以等概率（1/n）跳转到任何网页，再按照阻尼系数 d，对这个等概率（1/n）与存在链接的网页的转移概率进行线性组合，那么马尔科夫链一定存在平稳分布，一定可以得到网页的 PageRank 值。

所以 PageRank 的定义意味着网页浏览者按照以下方式在网上随机游走：以概率 d 按照存在的超链接随机跳转，以等概率从超链接跳转到下一个页面；或以概率(1-d)进行完全随机跳转，这时以等概率（1/n）跳转到任意网页。

PageRank 的计算是一个迭代过程，先假设一个初始的 PageRank 分布，通过迭代，不断计算所有网页的 PageRank 值，直到收敛为止，也就是：

![https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190518062629499-1904037096.png](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTYzMDQ3OC8yMDE5MDUvMTYzMDQ3OC0yMDE5MDUxODA2MjYyOTQ5OS0xOTA0MDM3MDk2LnBuZw)

## 2、TextRank算法

在文本自动摘要的案例中，TextRank 和 PageRank 的相似之处在于：

- 用句子代替网页
- 任意两个句子的相似性等价于网页转换概率
- 相似性得分存储在一个方形矩阵中，类似于 PageRank 的矩阵 M

不过公式有些小的差别，那就是用句子的相似度类比于网页转移概率，用归一化的句子相似度代替了 PageRank 中相等的转移概率，这意味着在 TextRank 中，所有节点的转移概率不会完全相等。

![https://img2018.cnblogs.com/blog/1630478/201905/1630478-20190518063625545-947712994.png](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9pbWcyMDE4LmNuYmxvZ3MuY29tL2Jsb2cvMTYzMDQ3OC8yMDE5MDUvMTYzMDQ3OC0yMDE5MDUxODA2MzYyNTU0NS05NDc3MTI5OTQucG5n)

然后迭代过程就和 PageRank 一致了。

## 3、TextRank做单领域多文本的自动摘要

用 TextRank 做单领域多文本的自动摘要的过程如下：

- 把所有文章整合成文本数据，并把文本分割成单个句子；
- 用 WordAVG 的方法，将每个句子中所有单词的词向量合并为句子的向量表示；
- 计算句子向量间的相似性并存放在矩阵中，作为转移概率矩阵 M；
- 然后将转移概率矩阵转换为以句子为节点、相似性得分为边的图结构，用于句子 TextRank 计算；
- 对句子按照 TextRank 值进行排序，排名最靠前的 n 个句子作为摘要。

好的，那下面我们就用 TextRank 算法，以及按照上面的流程，做一个新闻自动摘要的小案例。

# 二、基于TextRank的中文新闻摘要

参考了一篇用 TextRank 做英文新闻摘要的文章。

> 1、文章：《手把手|基于 TextRank 算法的文本摘要（附 Python 代码）》 https://mp.weixin.qq.com/s/fGaEYvo3WYKdzA3r8l6O3g
>
> 2、github 地址 ：https://github.com/prateekjoshi565/textrank\_text\_summarization

本文要处理的新闻一共 3 篇，都是关于证监会主席易会满同志新官上任的报道，新闻的大致内容是易会满同志怎么对中国资本市场的改革指点江山。

文档的原网页（看到百家号，不要鄙视我）：

- [https://baijiahao.baidu.com/s?id=1626615436040775944&wfr=spider&for=pc](https://baijiahao.baidu.com/s?id=1626615436040775944&wfr=spider&for=pc)
- [https://baijiahao.baidu.com/s?id=1626670136476331971&wfr=spider&for=pc](https://baijiahao.baidu.com/s?id=1626670136476331971&wfr=spider&for=pc)
- [http://finance.sina.com.cn/roll/2019-02-28/doc-ihrfqzka9798377.shtml](http://finance.sina.com.cn/roll/2019-02-28/doc-ihrfqzka9798377.shtml)

这个小实践的 github：https://github.com/DengYangyong/textrank_summarization

好，那就开始。

## 1、整合文档，划分句子

首先把文档读入，放在列表中，可以看到，有些句子已经被划分出来了。

> \['信息量巨大！易会满首秀，直面科创板 8 大问题，对散户加速入场笑而不语……',
>
> '每日经济新闻',
>
> '02-2717:56',
>
> '每经编辑：郭鑫 王晓波',
>
> '图片来源：新华社记者 李鑫 摄',
>
> '易会满上任一个月，还没有在公开场合说过一句话。',
>
> '2 月 27 日下午三点半开始，中国证监会主席易会满在北京国新办出席其首场新闻发布会，离发布会开始前两小时现场已经座无虚席，只等易主席来到现场。此外，副主席李超、副主席方星海，上海证券交易所理事长黄红元等也共同出席。',  
> ...\]

不过通过观察，我们可以发现存在两个问题：

一是以\[。？！；\]作为句子的分隔符，那么列表中的每个字符串元素中可能有多个句子；

二是每个字符串元素可能以\[：，\]结尾，也就是说可能是一个不完整的句子。

考虑到这只是一个小案例，所以就没花太多时间，仅仅处理一下第一个问题，把句子按照\[。？！；\]进行划分，如果字符串元素是不完整的句子，那也作为一句。

```python
import numpy as np
import pandas as pd
import re,os,jieba
from itertools import chain
 
"""第一步：把文档划分成句子"""
 
# 文档所在的文件夹
c_root = os.getcwd()+os.sep+"cnews"+os.sep  
 
sentences_list = []
for file in os.listdir(c_root): 
    fp = open(c_root+file,'r',encoding="utf8")
    for line in fp.readlines():
        if line.strip():
            # 把元素按照[。！；？]进行分隔，得到句子。
            line_split = re.split(r'[。！；？]',line.strip())
            # [。！；？]这些符号也会划分出来，把它们去掉。
            line_split = [line.strip() for line in line_split if line.strip() not in ['。','！','？','；'] and len(line.strip())>1]
            sentences_list.append(line_split)
sentences_list = list(chain.from_iterable(sentences_list))
print("前10个句子为：\n")
print(sentences_list[:10])
```

前 10 个句子为：

> \['信息量巨大',
>
> '易会满首秀，直面科创板 8 大问题，对散户加速入场笑而不语……',
>
> '每日经济新闻',
>
> '02-2717:56',  
> '每经编辑：郭鑫 王晓波',
>
> '图片来源：新华社记者 李鑫 摄',
>
> '易会满上任一个月，还没有在公开场合说过一句话',
>
> '2 月 27 日下午三点半开始，中国证监会主席易会满在北京国新办出席其首场新闻发布会，离发布会开始前两小时现场已经座无虚席，只等易主席来到现场',
>
> '此外，副主席李超、副主席方星海，上海证券交易所理事长黄红元等也共同出席',
>
> '这可能是这个月国内关注的人最多的一场新闻发布会了'\]

## 2、文本预处理

文本预处理包括去除停用词和非汉字字符，并进行分词。处理的过程要保证处理之后的句子的数量和处理之前的一样，因为后面我们计算了每个句子的 textrank 值之后，需要根据 textrank 值的大小，取出相应的句子作为摘要。

比如 '02-2717:56' 这个句子整个被过滤了，那就令这个句子为\[\]，下面也会给它一个句子的向量表示，只是元素都为 0。

```python
"""第二步：文本预处理，去除停用词和非汉字字符,并进行分词"""
 
#创建停用词列表
stopwords = [line.strip() for line in open('./stopwords.txt',encoding='UTF-8').readlines()]
 
# 对句子进行分词
def seg_depart(sentence):
    # 去掉非汉字字符
    sentence = re.sub(r'[^\u4e00-\u9fa5]+','',sentence)
    sentence_depart = jieba.cut(sentence.strip())
    word_list = []
    for word in sentence_depart:
        if word not in stopwords:
            word_list.append(word)   
    # 如果句子整个被过滤掉了，如：'02-2717:56'被过滤，那就返回[],保持句子的数量不变
    return word_list
 
sentence_word_list = []
for sentence in sentences_list:   
    line_seg = seg_depart(sentence)
    sentence_word_list.append(line_seg)
print("一共有",len(sentences_list),'个句子。\n')
print("前10个句子分词后的结果为：\n",sentence_word_list[:10])
 
# 保证处理后句子的数量不变，我们后面才好根据textrank值取出未处理之前的句子作为摘要。
if len(sentences_list) == len(sentence_word_list):
    print("\n数据预处理后句子的数量不变！")
```

一共有 347 个句子。

前 10 个句子分词后的结果为：

> \[\['信息量'\],  
> \['易会', '满首秀', '直面', '科创板', '散户', '加速', '入场', '笑', '不语'\],  
> \['每日', '经济', '新闻'\],  
> \[\],  
> \['每经', '编辑', '郭鑫', '王晓波'\],  
> \['图片', '来源', '李鑫', '摄'\],  
> \['易会', '上任', '一个月', '公开场合', '说', '一句', '话'\],  
> \['三点', '中国证监会', '主席', '易会', '北京', '国新办', '出席', '首场', '新闻', '发布会', '发布会', '前', '两', '小时', '现场', '座无虚席', '易', '主席', '来到', '现场'\],  
> \['副', '主席', '李超', '副', '主席', '星海', '上海证券交易所', '理事长', '黄红元', '出席'\],  
> \['国内', '关注', '一场', '新闻', '发布会'\]\]

数据预处理后句子的数量不变！

## 3、加载word2vec词向量

从这里下载了金融新闻 word2vec 词向量：https://github.com/Embedding/Chinese-Word-Vectors。

词向量是 300 维的，字和词语都有。我们把词向量加载进来，做成一个字典，共有 467140 个词语或字。

```python
"""第三步：准备词向量"""
 
word_embeddings = {}
f = open('./sgns.financial.char', encoding='utf-8')
for line in f:
    # 把第一行的内容去掉
    if '467389 300\n' not in line:
        values = line.split()
        # 第一个元素是词语
        word = values[0]
        embedding = np.asarray(values[1:], dtype='float32')
        word_embeddings[word] = embedding
f.close()
print("一共有"+str(len(word_embeddings))+"个词语/字。")
```

一共有 467140 个词语/字。

## 4、得到词语的 embedding，用 WordAVG 作为句子的向量表示

WordAVG 也就是先得到句子中的所有词语的词向量，然后求词向量的平均，作为该句子的向量表示。WordAVG 可以用来计算句子的相似度。

```python
"""第四步：得到词语的embedding，用WordAVG作为句子的向量表示"""
 
sentence_vectors = []
for i in sentence_word_list:
    if len(i)!=0:
        # 如果句子中的词语不在字典中，那就把embedding设为300维元素为0的向量。
        # 得到句子中全部词的词向量后，求平均值，得到句子的向量表示
        v = sum([word_embeddings.get(w, np.zeros((300,))) for w in i])/(len(i))
    else:
        # 如果句子为[]，那么就向量表示为300维元素为0个向量。
        v = np.zeros((300,))
    sentence_vectors.append(v)
```

## 5、计算句子之间的余弦相似度，构成相似度矩阵

```python
"""第五步：计算句子之间的余弦相似度，构成相似度矩阵"""
sim_mat = np.zeros([len(sentences_list), len(sentences_list)])
 
from sklearn.metrics.pairwise import cosine_similarity
 
for i in range(len(sentences_list)):
  for j in range(len(sentences_list)):
    if i != j:
      sim_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,300), sentence_vectors[j].reshape(1,300))[0,0]
print("句子相似度矩阵的形状为：",sim_mat.shape)
```

句子相似度矩阵的形状为： (347, 347)

## 6、迭代得到句子的textrank值，排序并取出摘要

以句子为节点、相似性得分为转移概率，构建图结构，然后迭代得到句子的 TextRank 分数。

对句子按照 TextRank 值进行降序排序，取出排名最靠前的 10 个句子作为摘要。

```python
"""第六步：迭代得到句子的textrank值，排序并取出摘要"""
import networkx as nx
 
# 利用句子相似度矩阵构建图结构，句子为节点，句子相似度为转移概率
nx_graph = nx.from_numpy_array(sim_mat)
 
# 得到所有句子的textrank值
scores = nx.pagerank(nx_graph)
 
# 根据textrank值对未处理的句子进行排序
ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences_list)), reverse=True)
 
# 取出得分最高的前10个句子作为摘要
sn = 10
for i in range(sn):
    print("第"+str(i+1)+"条摘要：\n\n",ranked_sentences[i][1],'\n')
```

> 第 1 条摘要：
>
> 在新闻发布会上，易会满表示，我到证监会工作今天是 31 天，刚刚满月，是资本市场的新兵，从市场参与者到监管者，角色转换角色挑战很大，如履薄冰，不敢懈怠，唯恐辜负中央信任和市场期待，这也是我做好工作的动力，近期加强调查研究，和部门协作维护市场平稳发展，维护科创板前期基础工作
>
> 第 2 条摘要：
>
> 易会满在新闻发布会上表示，防止发生系统性风险是底线和根本任务，当前受国内外多种因素影响，资本市场风险形式严峻复杂，证监会将坚持精准施策，做好股票质押私募基金、场外配资和地方各类场所的重点领域风险的防范化解和处置工作，完善资本市场逆周期机制，健全及时反映风险波动系统，运用大数据、人工智能等手段对上市公司专业监管，平衡事前、事中、事后关系，监管端口前移，强化监管效能
>
> 第 3 条摘要：
>
> 证监会将坚持精准施策，做好股票质押私募基金、场外配资和地方各类场所的重点领域风险的防范化解和处置工作，完善资本市场逆周期机制，健全及时反映风险波动系统，运用大数据、人工智能等手段对上市公司专业监管，平衡事前、事中、事后关系，监管端口前移，强化监管效能，切实做好打铁必须自身硬，做好中介机构和高管的强监管
>
> 第 4 条摘要：
>
> 这两者出发点和规则不同，我来证监会后不断学习研究，这么专业的问题证监会有专业化的团队，资本市场是大的生态，什么叫市场，应该是依靠市场各参与者，调动市场参与者，市场规律办事， 培养健康生态比什么都重要，这一考验和要求比专业更重要，生态建设好了，资本市场的健康发展才有保证
>
> 第 5 条摘要：
>
> 证监会副主席李超今天也给市场吃下定心丸：“对二级市场影响的问题，（科创板）设立时已经高度关注，在一系列的制度、规则层面作了相应安排
>
> 第 6 条摘要：
>
> 他表示，第一，设立科创板主要目的是增强资本市场对实体经济的包容性，更好地服务具有核心技术、行业领先、有良好发展前景和口碑的企业，通过改革进一步完善支持创新的资本形成机制
>
> 第 7 条摘要：
>
> 一是提高宏观思维能力，贴近市场各参与方，坚持市场导向、法治导向、监管导向，加强对资本市场宏观战略问题的研究思考，加强顶层设计，增强战略定力，稳步推进重点关注问题的改革创新，在改革中、在发展中破解难题
>
> 第 8 条摘要：
>
> 集体学习的通稿中，中央给资本市场定的“法治化”要求有不少，比如“把好市场入口和市场出口两道关，加强全程管”、“解决资本市场违法违规成本过低问题”
>
> 第 9 条摘要：
>
> 易会满表示，证监会将以 xijinping 新时代中国特色社会主义思想为指导，在国务院金融委的统一指挥协调下，主动加强与相关部委、地方党委政府和市场各方的沟通协作，努力形成工作合力，共同促进资本市场高质量发展
>
> 第 10 条摘要：
>
> 目前，资本市场已经回暖，这为改革提供了良好市场条件，我们要齐心协力，坚持“严标准、稳起步”的原则，积极做好落实和应对工作，注重各市场之间的平衡，确保改革平稳启动实施

Nice!

这样就完成了一个文本自动摘要的小实践了。

这是抽取型的摘要方法，以后再探索其他的文本自动摘要方法。