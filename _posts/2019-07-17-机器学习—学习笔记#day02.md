---
layout:     post
title:      机器学习—学习笔记#day02
subtitle:   机器学习
date:       2019-07-17
author:     DiCaprio
header-img: img/post-bg-spring.jpeg
catalog: true
tags:
    - 机器学习
    - Python
---

<p id="main-toc"><strong>目录</strong></p>


<p id="%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93" rel="nofollow" data-token="d5aa16c2642b3cb58f793a5e41bf0510" target="_self">总结</a></p>
<p id="1%E3%80%81sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E4%BC%B0%E8%AE%A1%E5%99%A8-toc" style="margin-left:0px;"><a href="#1%E3%80%81sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E4%BC%B0%E8%AE%A1%E5%99%A8" rel="nofollow" data-token="af6b21cae844b41ac8e153f143765c0b" target="_self">1、sklearn数据集与估计器</a></p>
<p id="sklearn%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:40px;"><a href="#sklearn%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow" data-token="08e4da4cce3c8e9128832d9b9e413024" target="_self">sklearn数据集</a></p>
<p id="1%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86-toc" style="margin-left:80px;"><a href="#1%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86" rel="nofollow" data-token="3ca2151711a87e1e6b9720a521871acf" target="_self">1、数据集划分</a></p>
<p id="2%E3%80%81sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E6%8E%A5%E5%8F%A3%E4%BB%8B%E7%BB%8D-toc" style="margin-left:80px;"><a href="#2%E3%80%81sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E6%8E%A5%E5%8F%A3%E4%BB%8B%E7%BB%8D" rel="nofollow" data-token="c93344c1341f12cfd63e660422be3e77" target="_self">2、sklearn数据集接口介绍</a></p>
<p id="sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86API-toc" style="margin-left:80px;"><a href="#sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86API" rel="nofollow" data-token="fd7927338d8583e5153feb1110f58147" target="_self">sklearn数据集划分API</a></p>
<p id="scikit-learn%E6%95%B0%E6%8D%AE%E9%9B%86API%E4%BB%8B%E7%BB%8D-toc" style="margin-left:80px;"><a href="#scikit-learn%E6%95%B0%E6%8D%AE%E9%9B%86API%E4%BB%8B%E7%BB%8D" rel="nofollow" data-token="67eb5480babc0fd9907512bbf95e6fb5" target="_self">scikit-learn数据集API介绍</a></p>
<p id="%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%94%E5%9B%9E%E7%9A%84%E7%B1%BB%E5%9E%8B-toc" style="margin-left:80px;"><a href="#%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%94%E5%9B%9E%E7%9A%84%E7%B1%BB%E5%9E%8B" rel="nofollow" data-token="6d09d9e0b621d5ca9354af492c78e443" target="_self">获取数据集返回的类型</a></p>
<p id="3%E3%80%81%20sklearn%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:80px;"><a href="#3%E3%80%81%20sklearn%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow" data-token="a17613e78e234ce4483d6165c17309fd" target="_self">3、 sklearn分类数据集</a></p>
<p id="%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E5%88%86%E5%89%B2-toc" style="margin-left:80px;"><a href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E5%88%86%E5%89%B2" rel="nofollow" data-token="20b41e2410f4d273a28ae57d17cd3f29" target="_self">数据集进行分割</a></p>
<p id="%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:80px;"><a href="#%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow" data-token="aa1d1d084dd712f90782bd9c518c1e5d" target="_self">用于分类的大数据集</a></p>
<p id="4%E3%80%81%20sklearn%E5%9B%9E%E5%BD%92%E6%95%B0%E6%8D%AE%E9%9B%86-toc" style="margin-left:80px;"><a href="#4%E3%80%81%20sklearn%E5%9B%9E%E5%BD%92%E6%95%B0%E6%8D%AE%E9%9B%86" rel="nofollow" data-token="13c8d2bbd8cbda6d9634e56480a4ddb9" target="_self">4、 sklearn回归数据集</a></p>
<p id="%E8%BD%AC%E6%8D%A2%E5%99%A8%E7%B1%BB(Transformer)-toc" style="margin-left:80px;"><a href="#%E8%BD%AC%E6%8D%A2%E5%99%A8%E7%B1%BB(Transformer)" rel="nofollow" data-token="118e6db7a99b3c7bf20eacc5870ebc66" target="_self">转换器类(Transformer)</a></p>
<p id="%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0-%E4%BC%B0%E8%AE%A1%E5%99%A8-toc" style="margin-left:80px;"><a href="#%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0-%E4%BC%B0%E8%AE%A1%E5%99%A8" rel="nofollow" data-token="09b7cbcf079f4c6352fff5566b982c49" target="_self">算法的实现-估计器</a></p>
<p id="%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B-toc" style="margin-left:80px;"><a href="#%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B" rel="nofollow" data-token="aa5c6d49ce30f70d59c75fea2994a564" target="_self">数据类型</a></p>
<p id="2%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95(KNN)-toc" style="margin-left:0px;"><a href="#2%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95(KNN)" rel="nofollow" data-token="c3caf91a477e0e00094053677aa4b727" target="_self">2、分类算法-k近邻算法(KNN)</a></p>
<p id="%E8%AE%A1%E7%AE%97%E8%B7%9D%E7%A6%BB%E5%85%AC%E5%BC%8F-toc" style="margin-left:80px;"><a href="#%E8%AE%A1%E7%AE%97%E8%B7%9D%E7%A6%BB%E5%85%AC%E5%BC%8F" rel="nofollow" data-token="6c6b1f5d49bcb9011e9d230e90754648" target="_self">计算距离公式</a></p>
<p id="sklearn%20k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95API-toc" style="margin-left:80px;"><a href="#sklearn%20k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95API" rel="nofollow" data-token="0514df7a8574e7068d11fe6facc1a844" target="_self">sklearn k-近邻算法API</a></p>
<p id="3%E3%80%81k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B-toc" style="margin-left:0px;"><a href="#3%E3%80%81k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B" rel="nofollow" data-token="fa18667a188eb10836fa1f72886b2792" target="_self">3、k-近邻算法实例</a></p>
<p id="k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B-%E9%A2%84%E6%B5%8B%E5%85%A5%E4%BD%8F%E4%BD%8D%E7%BD%AE-toc" style="margin-left:40px;"><a href="#k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B-%E9%A2%84%E6%B5%8B%E5%85%A5%E4%BD%8F%E4%BD%8D%E7%BD%AE" rel="nofollow" data-token="e15670974cc56b9ba5f7cbd66d37d082" target="_self">k近邻算法实例-预测入住位置</a></p>
<p id="%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86-toc" style="margin-left:40px;"><a href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86" rel="nofollow" data-token="f4873c589a9e8427ef019e5fb1190d8e" target="_self">数据的处理</a></p>
<p id="k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E4%BC%98%E7%BC%BA%E7%82%B9-toc" style="margin-left:40px;"><a href="#k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E4%BC%98%E7%BC%BA%E7%82%B9" rel="nofollow" data-token="b9c4a24cac2b996e27a1f0a43b769f65" target="_self">k-近邻算法优缺点</a></p>
<p id="4%E3%80%81%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0-toc" style="margin-left:0px;"><a href="#4%E3%80%81%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0" rel="nofollow" data-token="6cba8725e09c130927eb1b38ae8412c0" target="_self">4、分类模型的评估</a></p>
<p id="%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5-toc" style="margin-left:80px;"><a href="#%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5" rel="nofollow" data-token="60cafaaa7d2d60ea29db29d2671dd8fb" target="_self">混淆矩阵</a></p>
<p id="%E7%B2%BE%E7%A1%AE%E7%8E%87(Precision)%E4%B8%8E%E5%8F%AC%E5%9B%9E%E7%8E%87(Recall)-toc" style="margin-left:80px;"><a href="#%E7%B2%BE%E7%A1%AE%E7%8E%87(Precision)%E4%B8%8E%E5%8F%AC%E5%9B%9E%E7%8E%87(Recall)" rel="nofollow" data-token="8617e52c374dcf64ccfbc275f2ffb014" target="_self">精确率(Precision)与召回率(Recall)</a></p>
<p id="%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0API-toc" style="margin-left:80px;"><a href="#%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0API" rel="nofollow" data-token="3d510ff72411ec3cdbb0e78e845a5491" target="_self">分类模型评估API</a></p>
<p id="classification_report-toc" style="margin-left:80px;"><a href="#classification_report" rel="nofollow" data-token="03727b7ffc6ab256620a81f6ca265a30" target="_self">classification_report</a></p>
<p id="5%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95-toc" style="margin-left:0px;"><a href="#5%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95" rel="nofollow" data-token="1535298713869ebe279ee8eaf440b87e" target="_self">5、分类算法-朴素贝叶斯算法</a></p>
<p id="1%E3%80%81%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80-toc" style="margin-left:40px;"><a href="#1%E3%80%81%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80" rel="nofollow" data-token="e1c3f515c5557aa5ca5a65f60664ae19" target="_self">1、概率基础</a></p>
<p id="%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E5%92%8C%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87-toc" style="margin-left:80px;"><a href="#%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E5%92%8C%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87" rel="nofollow" data-token="3ff310def15422a942ed2acc16a591a8" target="_self">联合概率和条件概率</a></p>
<p id="2%E3%80%81%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BB%8B%E7%BB%8D-toc" style="margin-left:40px;"><a href="#2%E3%80%81%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BB%8B%E7%BB%8D" rel="nofollow" data-token="9ee86bcab67cc43094c9eb3df9e38f90" target="_self">2、朴素贝叶斯介绍</a></p>
<p id="%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F-toc" style="margin-left:80px;"><a href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F" rel="nofollow" data-token="ea044cdfaa5433815cb803580ec9309a" target="_self">朴素贝叶斯-贝叶斯公式</a></p>
<p id="%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91-toc" style="margin-left:80px;"><a href="#%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91" rel="nofollow" data-token="5420755674159e8732f1d52b288d73a0" target="_self">拉普拉斯平滑</a></p>
<p id="sklearn%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9E%E7%8E%B0API-toc" style="margin-left:80px;"><a href="#sklearn%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9E%E7%8E%B0API" rel="nofollow" data-token="f23dd871eb680d65446d9f7dbf573754" target="_self">sklearn朴素贝叶斯实现API</a></p>
<p id="MultinomialNB-toc" style="margin-left:80px;"><a href="#MultinomialNB" rel="nofollow" data-token="ce25f1b8dcebd3f745a971a91bbba8cf" target="_self">MultinomialNB</a></p>
<p id="6%E3%80%81%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B-toc" style="margin-left:0px;"><a href="#6%E3%80%81%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B" rel="nofollow" data-token="e86b3a218fec59421f3d772a04f8b89b" target="_self">6、朴素贝叶斯算法实例</a></p>
<p id="%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A1%88%E4%BE%8B%E6%B5%81%E7%A8%8B-toc" style="margin-left:80px;"><a href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A1%88%E4%BE%8B%E6%B5%81%E7%A8%8B" rel="nofollow" data-token="b6fac4fe107df86b378d11d37ef11cb1" target="_self">朴素贝叶斯案例流程</a></p>
<p id="%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E4%BC%98%E7%BC%BA%E7%82%B9-toc" style="margin-left:80px;"><a href="#%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E4%BC%98%E7%BC%BA%E7%82%B9" rel="nofollow" data-token="b950dc6e0c93c139e3c077467b5696bc" target="_self">朴素贝叶斯分类优缺点</a></p>
<p id="7%E3%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98-toc" style="margin-left:0px;"><a href="#7%E3%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98" rel="nofollow" data-token="c95bdb9f5c1d22573acba07a1f462b4c" target="_self">7、模型的选择与调优</a></p>
<p id="%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%BF%87%E7%A8%8B-toc" style="margin-left:80px;"><a href="#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%BF%87%E7%A8%8B" rel="nofollow" data-token="ab69f1c3676c2303b5eb4e5d76d24af9" target="_self">交叉验证过程</a></p>
<p id="%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2-toc" style="margin-left:80px;"><a href="#%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2" rel="nofollow" data-token="ac216ddf06cc65659792f92f8e8fdd2a" target="_self">超参数搜索-网格搜索</a></p>
<p id="%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2API-toc" style="margin-left:80px;"><a href="#%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2API" rel="nofollow" data-token="0f6ee8457d9fe9ace014da137fa464a7" target="_self">超参数搜索-网格搜索API</a></p>
<p id="GridSearchCV-toc" style="margin-left:80px;"><a href="#GridSearchCV" rel="nofollow" data-token="b92ed477664e0960425927058ef9cbd2" target="_self">GridSearchCV</a></p>
<p id="8%E3%80%81%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-toc" style="margin-left:0px;"><a href="#8%E3%80%81%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97" rel="nofollow" data-token="3b6ce62a043e39d0c44f234470258bf2" target="_self">8、决策树与随机森林</a></p>
<p id="%E5%86%B3%E7%AD%96%E6%A0%91-toc" style="margin-left:40px;"><a href="#%E5%86%B3%E7%AD%96%E6%A0%91" rel="nofollow" data-token="1420df9b6cbce7fc29cf338d69669138" target="_self">决策树</a></p>
<p id="%E8%AE%A4%E8%AF%86%E5%86%B3%E7%AD%96%E6%A0%91-toc" style="margin-left:80px;"><a href="#%E8%AE%A4%E8%AF%86%E5%86%B3%E7%AD%96%E6%A0%91" rel="nofollow" data-token="971754a85191f6361b9045e81439cd2d" target="_self">认识决策树</a></p>
<p id="%E4%BF%A1%E6%81%AF%E7%9A%84%E5%BA%A6%E9%87%8F%E5%92%8C%E4%BD%9C%E7%94%A8-toc" style="margin-left:80px;"><a href="#%E4%BF%A1%E6%81%AF%E7%9A%84%E5%BA%A6%E9%87%8F%E5%92%8C%E4%BD%9C%E7%94%A8" rel="nofollow" data-token="176a6635095fd9673eb6a2b1c70ffd76" target="_self">信息的度量和作用</a></p>
<p id="%E4%BF%A1%E6%81%AF%E7%86%B5-toc" style="margin-left:80px;"><a href="#%E4%BF%A1%E6%81%AF%E7%86%B5" rel="nofollow" data-token="0cabc3579b756582a3a03e4a14fd10b1" target="_self">信息熵</a></p>
<p id="%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%88%92%E5%88%86%E4%BE%9D%E6%8D%AE%E4%B9%8B%E4%B8%80-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A-toc" style="margin-left:80px;"><a href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%88%92%E5%88%86%E4%BE%9D%E6%8D%AE%E4%B9%8B%E4%B8%80-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A" rel="nofollow" data-token="d01cfd0425d53c750ba39078ddb05769" target="_self">决策树的划分依据之一-信息增益</a></p>
<p id="%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%9A%84%E8%AE%A1%E7%AE%97-toc" style="margin-left:80px;"><a href="#%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%9A%84%E8%AE%A1%E7%AE%97" rel="nofollow" data-token="5058162f2f6cf18bd36a3e48d073cc34" target="_self">信息增益的计算</a></p>
<p id="%E5%B8%B8%E8%A7%81%E5%86%B3%E7%AD%96%E6%A0%91%E4%BD%BF%E7%94%A8%E7%9A%84%E7%AE%97%E6%B3%95-toc" style="margin-left:80px;"><a href="#%E5%B8%B8%E8%A7%81%E5%86%B3%E7%AD%96%E6%A0%91%E4%BD%BF%E7%94%A8%E7%9A%84%E7%AE%97%E6%B3%95" rel="nofollow" data-token="cc90c07207c1aac3fad21a15e17c6b75" target="_self">常见决策树使用的算法</a></p>
<p id="sklearn%E5%86%B3%E7%AD%96%E6%A0%91API-toc" style="margin-left:80px;"><a href="#sklearn%E5%86%B3%E7%AD%96%E6%A0%91API" rel="nofollow" data-token="46aeebb1c8a76e986a34b49591c090ff" target="_self">sklearn决策树API</a></p>
<p id="%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B-toc" style="margin-left:80px;"><a href="#%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B" rel="nofollow" data-token="f22ad929b9ad5c3e0b4fae83e7ba8b21" target="_self">泰坦尼克号乘客生存分类模型</a></p>
<p id="%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%BB%93%E6%9E%84%E3%80%81%E6%9C%AC%E5%9C%B0%E4%BF%9D%E5%AD%98-toc" style="margin-left:80px;"><a href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%BB%93%E6%9E%84%E3%80%81%E6%9C%AC%E5%9C%B0%E4%BF%9D%E5%AD%98" rel="nofollow" data-token="5b6ba27653d2332e0d866f6ccf909a3a" target="_self">决策树的结构、本地保存</a></p>
<p id="%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E4%BB%A5%E5%8F%8A%E6%94%B9%E8%BF%9B-toc" style="margin-left:80px;"><a href="#%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E4%BB%A5%E5%8F%8A%E6%94%B9%E8%BF%9B" rel="nofollow" data-token="9062dea1d1740bdf313d9efbd9c98fab" target="_self">决策树的优缺点以及改进</a></p>
<p id="%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-toc" style="margin-left:40px;"><a href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97" rel="nofollow" data-token="3fb512493e81463a2fe7aebdcb9404ce" target="_self">随机森林</a></p>
<p id="%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-toc" style="margin-left:80px;"><a href="#%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97" rel="nofollow" data-token="5302b8c63e3570b50920db80742dc1da" target="_self">集成学习方法-随机森林</a></p>
<p id="%E4%BB%80%E4%B9%88%E6%98%AF%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-toc" style="margin-left:80px;"><a href="#%E4%BB%80%E4%B9%88%E6%98%AF%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97" rel="nofollow" data-token="0af3083667fe0168f80c146deaac8766" target="_self">什么是随机森林</a></p>
<p id="%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97API-toc" style="margin-left:80px;"><a href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97API" rel="nofollow" data-token="b01bd36f0ddf0ef8b6e3d927c3428040" target="_self">随机森林API</a></p>
<p id="%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E4%BC%98%E7%82%B9-toc" style="margin-left:80px;"><a href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E4%BC%98%E7%82%B9" rel="nofollow" data-token="ec5807ef67ea4588d710f84135fa608b" target="_self">随机森林的优点</a></p>
<hr id="hr-toc"><h1 id="%E6%80%BB%E7%BB%93"><a name="t0"></a>总结</h1>

<p><img alt="" class="has" src="https://img-blog.csdnimg.cn/20190717134518183.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70"></p>
<h1 id="1%E3%80%81sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E4%BC%B0%E8%AE%A1%E5%99%A8" style="margin-left:0in;"><a name="t1"></a><span style="color:#000000;">1、</span><span style="color:#000000;">sklearn</span><span style="color:#000000;">数据集与估计器</span></h1>
<h2 id="sklearn%E6%95%B0%E6%8D%AE%E9%9B%86" style="margin-left:0in;"><a name="t2"></a><span style="color:#0070c0;">sklearn</span><span style="color:#0070c0;">数据集</span></h2>
<h3 id="1%E3%80%81%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86" style="margin-left:0in;"><a name="t3"></a><span style="color:#000000;">1</span><span style="color:#000000;">、数据集划分</span></h3>
<p style="margin-left:0in;"><span style="color:#000000;">机器学习一般的数据集会划分为两个部分：</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">训练数据：用于训练，</span><span style="color:#ff0000;">构建模型</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">测试数据：在模型检验时使用，用于</span><span style="color:#ff0000;">评估模型是否有效</span></p>
<p style="margin-left:0in;"><img alt="" class="has" height="51" src="https://img-blog.csdnimg.cn/20190706145536585.png" width="375"><img alt="" class="has" height="28" src="https://img-blog.csdnimg.cn/20190706145542224.png" width="129"></p>
<p style="margin-left:0in;"><span style="color:#ff0000;">把样本划分一部分给测试集</span></p>
<h3 id="2%E3%80%81sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E6%8E%A5%E5%8F%A3%E4%BB%8B%E7%BB%8D" style="margin-left:0in;"><a name="t4"></a><span style="color:#000000;">2</span><span style="color:#000000;">、</span><span style="color:#000000;">sklearn</span><span style="color:#000000;">数据集接口介绍</span></h3>
<h3 id="sklearn%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86API" style="margin-left:0in;"><a name="t5"></a><span style="color:#e46c0a;">sklearn</span><span style="color:#e46c0a;">数据集划分</span><span style="color:#e46c0a;">API</span></h3>
<p style="margin-left:0in;"><span style="color:#000000;">sklearn.model_selection.</span><span style="color:#ff0000;">train_test_split</span></p>
<h3 id="scikit-learn%E6%95%B0%E6%8D%AE%E9%9B%86API%E4%BB%8B%E7%BB%8D" style="margin-left:0in;"><a name="t6"></a><span style="color:#7030a0;">scikit-learn</span><span style="color:#7030a0;">数据集</span><span style="color:#7030a0;">API</span><span style="color:#7030a0;">介绍</span></h3>
<blockquote>
<p>•<span style="color:#000000;">sklearn.</span><span style="color:#ff0000;">datasets</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">加载获取流行数据集</span></p>
<p style="text-indent:0;">•<span style="color:#ff0000;">datasets.load</span><span style="color:#ff0000;">_*()</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">获取小规模数据集，数据包含在</span><span style="color:#000000;">datasets</span><span style="color:#000000;">里</span></p>
<p>•<span style="color:#ff0000;">datasets.fetch</span><span style="color:#ff0000;">_*(</span><span style="color:#ff0000;">data_home</span><span style="color:#ff0000;">=None)</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">获取大规模数据集，需要从网络上下载，函</span></p>
<p style="margin-left:.5in;">&nbsp; <span style="color:#000000;">数的第一个参数是</span><span style="color:#000000;">data_home</span><span style="color:#000000;">，表示数据集</span></p>
<p style="margin-left:.5in;">&nbsp; <span style="color:#000000;">下载的目录</span><span style="color:#000000;">,</span><span style="color:#000000;">默认是 </span><span style="color:#000000;">~/</span><span style="color:#000000;">scikit_learn_data</span><span style="color:#000000;">/</span></p>
</blockquote>

<h3 id="%E8%8E%B7%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%94%E5%9B%9E%E7%9A%84%E7%B1%BB%E5%9E%8B"><a name="t7"></a><span style="color:#e46c0a;">获取数据集返回的类型</span></h3>
<blockquote>
<p>•<span style="color:#000000;">load*</span><span style="color:#000000;">和</span><span style="color:#000000;">fetch*</span><span style="color:#000000;">返回的数据类型</span><span style="color:#000000;">datasets.base.Bunch</span><span style="color:#000000;">(</span><span style="color:#ff0000;">字典格式</span><span style="color:#000000;">)</span></p>

<p>•<span style="color:#000000;">data</span><span style="color:#000000;">：特征数据数组，是 </span><span style="color:#000000;">[</span><span style="color:#000000;">n_samples</span><span style="color:#000000;"> * </span><span style="color:#000000;">n_features</span><span style="color:#000000;">] </span><span style="color:#000000;">的二维 numpy.ndarray</span> <span style="color:#000000;">数组</span></p>
<p>•<span style="color:#000000;">target</span><span style="color:#000000;">：标签数组，是 </span><span style="color:#000000;">n_samples</span> <span style="color:#000000;">的一维 </span><span style="color:#000000;">numpy.ndarray</span> <span style="color:#000000;">数组</span></p>
<p>•<span style="color:#000000;">DESCR</span><span style="color:#000000;">：数据描述</span></p>
<p>•<span style="color:#000000;">feature_names</span><span style="color:#000000;">：特征名</span><span style="color:#000000;">,</span><span style="color:#ff0000;">新闻数据，手写数字、回归数据集没有</span></p>
<p>•<span style="color:#000000;">target_names</span><span style="color:#000000;">：标签名</span><span style="color:#000000;">,</span><span style="color:#000000;">回归数据集没有</span></p>
</blockquote>

<h3 id="3%E3%80%81%20sklearn%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86" style="margin-left:0in;"><a name="t8"></a><span style="color:#000000;">3</span><span style="color:#000000;">、</span> <span style="color:#000000;">sklearn</span><span style="color:#000000;">分类数据集</span></h3>
<p id="%E2%80%8B" style="margin-left:0in;"><img alt="" class="has" height="402" src="https://img-blog.csdnimg.cn/20190706150046576.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="578"></p>
<pre class="has" name="code"><code class="hljs python"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-keyword">from</span> sklearn.datasets <span class="hljs-keyword">import</span> load_iris</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">li = load_iris()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">"获取特征值"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(li.data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">"目标值"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(li.target)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(li.DESCR)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre>
<p id="%E2%80%8B%C2%A0%E2%80%8B" style="margin-left:0in;"><img alt="" class="has" height="229" src="https://img-blog.csdnimg.cn/20190706150414364.png" width="251">&nbsp;<img alt="" class="has" height="125" src="https://img-blog.csdnimg.cn/20190706150426518.png" width="681"></p>
<p><img alt="" class="has" height="238" src="https://img-blog.csdnimg.cn/2019070615053893.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="556"></p>
<h3 id="%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E5%88%86%E5%89%B2" style="margin-left:0in;"><a name="t9"></a><span style="color:#7030a0;">数据集进行分割</span></h3>
<blockquote>
<p>•<span style="color:#000000;">sklearn.model_selection.train_test_split</span><span style="color:#000000;">(</span><span style="color:#000000;"><em>*arrays</em></span><span style="color:#000000;">,&nbsp;</span><span style="color:#000000;"><em>**options</em></span><span style="color:#000000;">)</span></p>

<p>•<span style="color:#000000;">x&nbsp; </span><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 数据集的特征值</span></p>
<p>•<span style="color:#000000;">y&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span><span style="color:#000000;">数据集的标签值</span></p>
<p>•<span style="color:#000000;">test_size</span><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 测试集的大小，一般为</span><span style="color:#000000;">float</span></p>
<p>•<span style="color:#000000;">random_state</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <span style="color:#000000;">随机数种子</span><span style="color:#000000;">,</span><span style="color:#000000;">不同的种子会造成不同的随机</span></p>
<p style="margin-left:.5in;"><span style="color:#000000;">采样结果。相同的种子采样结果相同。</span></p>
<p>•<span style="color:#000000;">return&nbsp; </span><span style="color:#000000;">训练集特征值，测试集特征值，训练标签，测试标签</span></p>
<p style="margin-left:.5in;"><span style="color:#000000;">(</span><span style="color:#000000;">默认随机取</span><span style="color:#000000;">)&nbsp; </span></p>
</blockquote>

<pre class="has" name="code"><code class="hljs python"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-comment"># 注意返回值, 训练集 train  x_train, y_train        测试集  test   x_test, y_test</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">x_train, x_test, y_train, y_test = train_test_split(li.data, li.target, test_size=<span class="hljs-number">0.25</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">"训练集特征值和目标值："</span>, x_train, y_train)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">"测试集特征值和目标值："</span>, x_test, y_test)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre>
<p style="margin-left:0in;"><img alt="" class="has" height="145" src="https://img-blog.csdnimg.cn/20190706151056770.png" width="344">&nbsp;<img alt="" class="has" height="139" src="https://img-blog.csdnimg.cn/20190706151110563.png" width="445"></p>
<h3 id="%E7%94%A8%E4%BA%8E%E5%88%86%E7%B1%BB%E7%9A%84%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86" style="margin-left:0in;"><a name="t10"></a><span style="color:#e46c0a;">用于分类的大数据集</span></h3>
<blockquote>
<p>•<span style="color:#333333;">sklearn.datasets.fetch_20newsgroups</span><span style="color:#333333;">(</span><span style="color:#ff0000;">data_home</span><span style="color:#ff0000;">=</span><span style="color:#ff0000;">None,subset</span><span style="color:#ff0000;">=‘train’</span><span style="color:#000000;">)</span></p>

<p>•<span style="color:#000000;">subset: 'train'</span><span style="color:#000000;">或者</span><span style="color:#000000;">'</span><span style="color:#000000;">test','all</span><span style="color:#000000;">'</span><span style="color:#000000;">，可选，选择要加载的数据集</span><span style="color:#000000;">.</span></p>
<p style="margin-left:.5in;"><span style="color:#000000;">训练集的“训练”，测试集的“测试”，两者的“全部”</span></p>
<p>•<span style="color:#000000;">datasets.clear_data_home</span><span style="color:#000000;">(</span><span style="color:#000000;">data_home</span><span style="color:#000000;">=None)</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">清除目录下的数据</span></p>
</blockquote>

<h3 id="4%E3%80%81%20sklearn%E5%9B%9E%E5%BD%92%E6%95%B0%E6%8D%AE%E9%9B%86" style="margin-left:0in;"><a name="t11"></a><span style="color:#000000;">4</span><span style="color:#000000;">、</span> <span style="color:#000000;">sklearn</span><span style="color:#000000;">回归数据集</span></h3>
<p><img alt="" class="has" height="379" src="https://img-blog.csdnimg.cn/20190706152000763.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="628"></p>
<pre class="has" name="code"><code class="hljs python"><ol class="hljs-ln"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">lb = load_boston()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">"获取特征值"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(lb.data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(<span class="hljs-string">"目标值"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(lb.target)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">print(lb.DESCR)</div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre>
<p><img alt="" class="has" height="246" src="https://img-blog.csdnimg.cn/2019070615215012.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="659"></p>
<h3 id="%E8%BD%AC%E6%8D%A2%E5%99%A8%E7%B1%BB(Transformer)"><a name="t12"></a><span style="color:#ff0000;">转换器类</span><span style="color:#ff0000;">(</span><span style="color:#ff0000;">Transformer)</span></h3>
<p><img alt="" class="has" height="531" src="https://img-blog.csdnimg.cn/20190706153122958.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="767"></p>
<h3 id="%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0-%E4%BC%B0%E8%AE%A1%E5%99%A8"><a name="t13"></a><span style="color:#0070c0;">算法的实现</span><span style="color:#0070c0;">-</span><span style="color:#0070c0;">估计器</span></h3>
<p><img alt="" class="has" height="292" src="https://img-blog.csdnimg.cn/20190706153211320.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="589"></p>
<p><img alt="" class="has" height="466" src="https://img-blog.csdnimg.cn/20190706153603112.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="530">&nbsp;<img alt="" class="has" height="439" src="https://img-blog.csdnimg.cn/20190706153738662.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="430"></p>
<h3 id="%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><a name="t14"></a><span style="color:#0070c0;">数据类型</span></h3>
<p><img alt="" class="has" height="290" src="https://img-blog.csdnimg.cn/20190706154335461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="612"></p>
<h1 id="2%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95(KNN)" style="margin-left:0in;"><a name="t15"></a><span style="color:#000000;">2</span><span style="color:#000000;">、分类算法</span><span style="color:#000000;">-k近邻算法</span><span style="color:#0070c0;">(KNN)</span></h1>
<p><img alt="" class="has" height="243" src="https://img-blog.csdnimg.cn/20190706160408793.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="806"></p>
<p style="margin-left:0in;"><span style="color:#000000;">定义：如果一个样本在特征空间中的</span><span style="color:#ff0000;">k</span><span style="color:#ff0000;">个最相似</span><span style="color:#ff0000;">(</span><span style="color:#ff0000;">即特征空间中最邻近</span><span style="color:#ff0000;">)</span><span style="color:#ff0000;">的样本中的大多数属于某一个类别</span><span style="color:#000000;">，则该样本也属于这个类别。</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">来源：</span><span style="color:#000000;">KNN</span><span style="color:#000000;">算法最早是由</span><span style="color:#000000;">Cover</span><span style="color:#000000;">和</span><span style="color:#000000;">Hart</span><span style="color:#000000;">提出的一种分类算法</span></p>
<h3 id="%E8%AE%A1%E7%AE%97%E8%B7%9D%E7%A6%BB%E5%85%AC%E5%BC%8F" style="margin-left:0in;"><a name="t16"></a><span style="color:#7030a0;">计算距离公式</span></h3>
<p style="margin-left:0in;"><span style="color:#000000;">两个样本的距离可以通过如下公式计算，又叫</span><span style="color:#ff0000;">欧式距离</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">比如说，</span><span style="color:#000000;">a(a1,a2,a3),b(b1,b2,b3)</span></p>
<p style="margin-left:0in;"><img alt="" class="has" height="40" src="https://img-blog.csdnimg.cn/20190706160550850.png" width="357"></p>
<p style="margin-left:0in;"><img alt="" class="has" height="24" src="https://img-blog.csdnimg.cn/20190706160851125.png" width="308"></p>
<h3 id="sklearn%20k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95API" style="margin-left:0in;"><a name="t17"></a><span style="color:#7030a0;">sklearn</span> <span style="color:#7030a0;">k-</span><span style="color:#7030a0;">近邻算法</span><span style="color:#7030a0;">API</span></h3>
<blockquote>
<p>•<span style="color:#000000;">sklearn.neighbors.</span><span style="color:#ff0000;">KNeighborsClassifier</span><span style="color:#000000;">(</span><span style="color:#000000;">n_neighbors</span><span style="color:#000000;">=5,algorithm='auto')</span></p>

<p style="text-indent:50px;">• <span style="color:#000000;">n_neighbors</span><span style="color:#000000;">：</span><span style="color:#000000;">int</span><span style="color:#000000;">,</span><span style="color:#000000;">可选（默认</span><span style="color:#000000;">= 5</span><span style="color:#000000;">），</span><span style="color:#000000;">k_neighbors</span><span style="color:#000000;">查询默认使用的邻居数 </span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">algorithm</span><span style="color:#000000;">：</span><span style="color:#000000;">{‘auto’</span><span style="color:#000000;">，</span><span style="color:#000000;">‘</span><span style="color:#000000;">ball_tree</span><span style="color:#000000;">’</span><span style="color:#000000;">，</span><span style="color:#000000;">‘</span><span style="color:#000000;">kd_tree</span><span style="color:#000000;">’</span><span style="color:#000000;">，</span><span style="color:#000000;">‘brute’}</span><span style="color:#000000;">，可选用于计算最近邻居的算法：</span><span style="color:#000000;">‘</span><span style="color:#000000;">ball_tree</span><span style="color:#000000;">’</span><span style="color:#000000;">将会使用 </span><span style="color:#000000;">BallTree</span><span style="color:#000000;">，</span><span style="color:#000000;">‘</span><span style="color:#000000;">kd_tree</span><span style="color:#000000;">’</span><span style="color:#000000;">将使用 </span><span style="color:#000000;">KDTree</span><span style="color:#000000;">。</span><span style="color:#000000;">‘auto’</span><span style="color:#000000;">将尝试根据传递给</span><span style="color:#000000;">fit</span><span style="color:#000000;">方法的值来决定最合适的算法。 </span><span style="color:#000000;">(</span><span style="color:#000000;">不同实现方式影响效率</span><span style="color:#000000;">)</span></p>
</blockquote>

<h1 id="3%E3%80%81k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B" style="margin-left:0in;"><a name="t18"></a><span style="color:#000000;">3</span><span style="color:#000000;">、</span><span style="color:#000000;">k-</span><span style="color:#000000;">近邻算法实例</span></h1>
<h2 id="k%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B-%E9%A2%84%E6%B5%8B%E5%85%A5%E4%BD%8F%E4%BD%8D%E7%BD%AE" style="margin-left:0in;"><a name="t19"></a><span style="color:#7030a0;">k</span><span style="color:#7030a0;">近邻算法实例</span><span style="color:#7030a0;">-</span><span style="color:#7030a0;">预测入住位置</span></h2>
<p><img alt="" class="has" height="320" src="https://img-blog.csdnimg.cn/20190706161308336.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="707"><img alt="" class="has" height="231" src="https://img-blog.csdnimg.cn/20190706161319390.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="582"></p>
<h2 id="%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86" style="margin-left:0in;"><a name="t20"></a><span style="color:#7030a0;">数据的处理</span></h2>
<p style="margin-left:0in;"><span style="color:#000000;">1</span><span style="color:#000000;">、缩小数据集范围</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">DataFrame.query</span><span style="color:#000000;">()</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">2</span><span style="color:#000000;">、处理日期数据</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">pd.to_datetime</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">pd.DatetimeIndex</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">3</span><span style="color:#000000;">、增加分割的日期数据</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">4</span><span style="color:#000000;">、删除没用的日期数据</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">pd.drop</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">5</span><span style="color:#000000;">、将</span><span style="color:#ff0000;">签到位置</span><span style="color:#000000;">少于</span><span style="color:#000000;">n</span><span style="color:#000000;">个用户的删除</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">place_count</span><span style="color:#000000;"> =</span><span style="color:#000000;">data.groupby</span><span style="color:#000000;">('</span><span style="color:#000000;">place_id</span><span style="color:#000000;">').aggregate(</span><span style="color:#000000;">np.count_nonzero</span><span style="color:#000000;">)</span><br><span style="color:#000000;">tf</span><span style="color:#000000;"> = </span><span style="color:#000000;">place_count</span><span style="color:#000000;">[</span><span style="color:#000000;">place_count</span><span style="color:#000000;">.row_id</span><span style="color:#000000;"> &gt; 3].</span><span style="color:#000000;">reset_index</span><span style="color:#000000;">()</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">data = data[data['</span><span style="color:#000000;">place_id</span><span style="color:#000000;">'].</span><span style="color:#000000;">isin</span><span style="color:#000000;">(</span><span style="color:#000000;">tf.place_id</span><span style="color:#000000;">)]</span></p>
<pre class="has" name="code"><code class="hljs python"><ol class="hljs-ln" style="width:1068px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">knncls</span><span class="hljs-params">()</span>:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string"><span class="hljs-string">"""</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    K-近邻预测用户签到位置</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    :return:None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 读取数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data = pd.read_csv(<span class="hljs-string">"./data/FBlocation/train.csv"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print(data.head(10))</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 处理数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 1、缩小数据,查询数据筛选</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data = data.query(<span class="hljs-string">"x &gt; 1.0 &amp;  x &lt; 1.25 &amp; y &gt; 2.5 &amp; y &lt; 2.75"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 处理时间的数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    time_value = pd.to_datetime(data[<span class="hljs-string">'time'</span>], unit=<span class="hljs-string">'s'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(time_value)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 把日期格式转换成 字典格式</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    time_value = pd.DatetimeIndex(time_value)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 构造一些特征</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data[<span class="hljs-string">'day'</span>] = time_value.day</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data[<span class="hljs-string">'hour'</span>] = time_value.hour</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data[<span class="hljs-string">'weekday'</span>] = time_value.weekday</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 把时间戳特征删除</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data = data.drop([<span class="hljs-string">'time'</span>], axis=<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 把签到数量少于n个目标位置删除</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    place_count = data.groupby(<span class="hljs-string">'place_id'</span>).count()  <span class="hljs-comment"># 分组统计个数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    tf = place_count[place_count.row_id &gt; <span class="hljs-number">3</span>].reset_index()  <span class="hljs-comment"># 保留了大于3次的数据，reset_index 重置索引，把列属性换成索引</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data = data[data[<span class="hljs-string">'place_id'</span>].isin(tf.place_id)]  <span class="hljs-comment"># 把tf.place_id在data['place_id']里的数据取出来，即取出大于3次的全部数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 取出数据当中的特征值和目标值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    y = data[<span class="hljs-string">'place_id'</span>]  <span class="hljs-comment"># 目标值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x = data.drop([<span class="hljs-string">'place_id'</span>], axis=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 删除place_id剩下就是特征值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行数据的分割训练集合测试集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="hljs-number">0.25</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 特征工程（标准化：让每一列的数据在同一个标准下进行计算） 不进行标准化时，准确率为2.7%</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    std = StandardScaler()  <span class="hljs-comment"># 训练特征值做标准化，测试特征值也要做标准化，目标值不用做标准化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 对测试集和训练集的特征值进行标准化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train = std.fit_transform(x_train)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_test = std.transform(x_test)  <span class="hljs-comment"># 不用fit（不用重新计算一次方差，平均值...）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行算法流程 # 超参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    knn = KNeighborsClassifier()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># fit， predict,score</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    knn.fit(x_train, y_train)  <span class="hljs-comment"># 输入数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 得出预测结果</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    y_predict = knn.predict(x_test)  <span class="hljs-comment"># 以测试集预测</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"预测的目标签到位置为："</span>, y_predict)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 得出预测准确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"预测的准确率:"</span>, knn.score(x_test, y_test))  <span class="hljs-comment"># 用x_test得出预测值与y_test比较</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> <span class="hljs-keyword">None</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre>
<h2 id="k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95%E4%BC%98%E7%BC%BA%E7%82%B9" style="margin-left:0in;"><a name="t21"></a><span style="color:#7030a0;">k-</span><span style="color:#7030a0;">近邻算法优缺点</span></h2>
<p>•<span style="color:#000000;">优点：</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">简单，易于理解，易于实现，</span><span style="color:#ff0000;">无需估计参数，无需训练</span></p>
<p>•<span style="color:#000000;">缺点：</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">懒惰算法，对测试样本分类时的计算量大，内存开销大</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">必须指定</span><span style="color:#000000;">K</span><span style="color:#000000;">值，</span><span style="color:#000000;">K</span><span style="color:#000000;">值选择不当则分类精度不能保证</span></p>
<p><strong>•</strong><span style="color:#000000;"><strong>使用场景：</strong>小数据场景，几千～几万样本，具体场景具体业务去测试，在实际案例基本不用。</span></p>
<p style="margin-left:0in;"><strong><span style="color:#000000;">k</span><span style="color:#000000;">值取多大？有什么影响？</span></strong></p>
<p style="margin-left:0in;"><span style="color:#000000;">k</span><span style="color:#000000;">值取很小：容易受异常点影响</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">k</span><span style="color:#000000;">值取很大：容易受最近数据太多导致比例变化</span></p>
<h1 id="4%E3%80%81%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%84%E4%BC%B0" style="margin-left:0in;"><a name="t22"></a><span style="color:#000000;">4</span><span style="color:#000000;">、分类模型的评估</span></h1>
<p>•<span style="color:#000000;">estimator.score</span><span style="color:#000000;">()</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">一般最常见使用的是</span><span style="color:#ff0000;">准确率</span><span style="color:#000000;">，即预测结果正确的百分比</span></p>
<h3 id="%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5"><a name="t23"></a><span style="color:#7030a0;">混淆矩阵</span></h3>
<p>•<span style="color:#333333;">在分类任务下，预测结果</span><span style="color:#333333;">(Predicted Condition)</span><span style="color:#333333;">与正确标记</span><span style="color:#333333;">(True Condition)</span><span style="color:#333333;">之间存在四种不同的组合，构成混淆矩阵</span><span style="color:#333333;">(</span><span style="color:#333333;">适用于多分类</span><span style="color:#333333;">)</span></p>
<p><img alt="" class="has" height="347" src="https://img-blog.csdnimg.cn/20190708150708512.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="638"></p>
<h3 id="%E7%B2%BE%E7%A1%AE%E7%8E%87(Precision)%E4%B8%8E%E5%8F%AC%E5%9B%9E%E7%8E%87(Recall)"><a name="t24"></a><span style="color:#7030a0;">精确率</span><span style="color:#7030a0;">(Precision)</span><span style="color:#7030a0;">与召回率</span><span style="color:#7030a0;">(Recall)</span></h3>
<p><img alt="" class="has" height="385" src="https://img-blog.csdnimg.cn/20190708150735899.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="595"></p>
<p>检查产品合格性主要考虑召回率的较多</p>
<h3 id="%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0API"><a name="t25"></a><span style="color:#7030a0;">分类模型评估</span><span style="color:#7030a0;">API</span></h3>
<blockquote>
<p>•<span style="color:#000000;">sklearn.</span><span style="color:#ff0000;">metrics.classification_report</span></p>

<h3 id="classification_report"><a name="t26"></a><span style="color:#e46c0a;">classification_report</span></h3>
<p>&nbsp;</p>
<p>•<span style="color:#000000;">sklearn.metrics.classification_report</span><span style="color:#000000;">(</span><span style="color:#000000;"><em>y_true</em></span><span style="color:#000000;">,&nbsp;</span><span style="color:#000000;"><em>y_pred</em></span><span style="color:#000000;">,&nbsp;</span><span style="color:#000000;"><em>target_names</em></span><span style="color:#000000;"><em>=None</em></span><span style="color:#000000;">)</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">y_true</span><span style="color:#000000;">：真实目标值</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">y_pred</span><span style="color:#000000;">：估计器预测目标值</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">target_names</span><span style="color:#000000;">：目标类别名称</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">return</span><span style="color:#000000;">：每个类别精确率与召回率</span></p>
</blockquote>

<h1 id="5%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95" style="margin-left:0in;"><a name="t27"></a><span style="color:#000000;">5</span><span style="color:#000000;">、分类算法</span><span style="color:#000000;">-</span><span style="color:#000000;">朴素贝叶斯算法</span></h1>
<h2 id="1%E3%80%81%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80" style="margin-left:0in;"><a name="t28"></a><span style="color:#000000;">1</span><span style="color:#000000;">、概率基础</span></h2>
<h3 id="%E8%81%94%E5%90%88%E6%A6%82%E7%8E%87%E5%92%8C%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87"><a name="t29"></a><span style="color:#7030a0;">联合概率和条件概率</span></h3>
<blockquote>
<p style="margin-left:0in;"><span style="color:#000000;">联合概率：</span><span style="color:#000000;">包含多个条件，且所有条件</span><span style="color:#000000;"><strong>同时</strong></span><span style="color:#000000;">成立的概率</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">记作：</span><span style="color:#ff0000;">P(A,B)&nbsp; &nbsp;P(A,B)=P(A)P(B)</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">条件概率：</span><span style="color:#000000;">就是事件</span><span style="color:#000000;"><em>A</em></span><span style="color:#000000;">在另外一个事件</span><span style="color:#000000;"><em>B</em></span><span style="color:#000000;">已经发生条件下的发生概率</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">记作：</span><span style="color:#ff0000;">P(A|B)</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">特性：</span><span style="color:#ff0000;">P(A1,A2|B) = P(A1|B)P(A2|B)</span></p>
<p style="margin-left:0in;"><span style="color:#ff0000;">注意：此条件概率的成立，是由于</span><span style="color:#ff0000;">A1,A2</span><span style="color:#ff0000;">相互独立的结果</span></p>
</blockquote>

<h2 id="2%E3%80%81%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BB%8B%E7%BB%8D" style="margin-left:0in;"><a name="t30"></a><span style="color:#000000;">2</span><span style="color:#000000;">、朴素贝叶斯介绍</span></h2>
<p><span style="color:#000000;">使用前提：特征独立（不独立时也可以使用，但是效果不好）</span></p>
<blockquote>
<p><span style="color:#f33b45;">“朴素”就是特征独立（条件独立）的意思</span></p>
</blockquote>

<h3 id="%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F"><a name="t31"></a><span style="color:#7030a0;">朴素贝叶斯</span><span style="color:#7030a0;">-</span><span style="color:#7030a0;">贝叶斯公式</span></h3>
<p><img alt="" class="has" height="271" src="https://img-blog.csdnimg.cn/2019070815103776.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="571"></p>
<p><img alt="" class="has" height="283" src="https://img-blog.csdnimg.cn/20190708151100878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="548"></p>
<blockquote>
<p><span style="color:#7030a0;">例：</span></p>

<p><img alt="" class="has" height="196" src="https://img-blog.csdnimg.cn/20190708152713991.png" width="586"></p>
<p><img alt="" class="has" height="113" src="https://img-blog.csdnimg.cn/2019070815293498.png" width="762"></p>
<p><img alt="" class="has" height="302" src="https://img-blog.csdnimg.cn/20190708153729667.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="694"><img alt="" class="has" height="149" src="https://img-blog.csdnimg.cn/20190708153740278.png" width="648"></p>
<p style="margin-left:0in;"><span style="color:#0070c0;">思考：属于某个类别为</span><span style="color:#0070c0;">0</span><span style="color:#0070c0;">，合适吗？</span></p>
</blockquote>

<h3 id="%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B9%B3%E6%BB%91"><a name="t32"></a><span style="color:#ff0000;">拉普拉斯平滑</span></h3>
<p style="margin-left:0in;"><span style="color:#000000;">问题：从上面的例子我们得到娱乐概率为</span><span style="color:#000000;">0</span><span style="color:#000000;">，这是不合理的，如果词频列表里面</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">有很多出现次数都为</span><span style="color:#000000;">0</span><span style="color:#000000;">，很可能计算结果都为零</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">解决方法：</span><span style="color:#ff0000;"><strong>拉普拉斯平滑系数</strong></span></p>
<blockquote>
<p style="margin-left:0in;"><img alt="" class="has" height="39" src="https://img-blog.csdnimg.cn/20190708153848713.png" width="154">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>

<p style="margin-left:0in;"><span style="color:#000000;"><em>𝛼</em></span><span style="color:#000000;"><em>为</em></span><span style="color:#000000;"><em>指定</em></span><span style="color:#000000;"><em>的</em></span><span style="color:#000000;"><em>系数</em></span><span style="color:#000000;">α</span><span style="color:#000000;">为</span><span style="color:#000000;">指定</span><span style="color:#000000;">的</span><span style="color:#000000;">系数</span><span style="color:#000000;">一般为</span><span style="color:#000000;">1</span><span style="color:#000000;">，</span><span style="color:#000000;">m</span><span style="color:#000000;">为训练文档中统计出的</span><span style="color:#ff0000;">特征词</span><span style="color:#000000;">个数</span></p>
</blockquote>

<p style="margin-left:0in;"><img alt="" class="has" height="60" src="https://img-blog.csdnimg.cn/20190708153949463.png" width="640"></p>
<h3 id="sklearn%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9E%E7%8E%B0API" style="margin-left:0in;"><a name="t33"></a><span style="color:#7030a0;">sklearn</span><span style="color:#7030a0;">朴素贝叶斯实现</span><span style="color:#7030a0;">API</span></h3>
<p>•<span style="color:#000000;">sklearn.naive_bayes.</span><span style="color:#ff0000;">MultinomialNB</span></p>
<h3 id="MultinomialNB" style="margin-left:0in;"><a name="t34"></a><span style="color:#e46c0a;">MultinomialNB</span></h3>
<blockquote>
<p>•<span style="color:#000000;">sklearn.naive_bayes.MultinomialNB</span><span style="color:#000000;">(</span><span style="color:#000000;"><em>alpha = 1.0</em></span><span style="color:#000000;">)</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">朴素贝叶斯分类</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">alpha</span><span style="color:#000000;">：拉普拉斯平滑系数</span></p>
</blockquote>

<h1 id="6%E3%80%81%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%AE%97%E6%B3%95%E5%AE%9E%E4%BE%8B" style="margin-left:0in;"><a name="t35"></a><span style="color:#000000;">6</span><span style="color:#000000;">、朴素贝叶斯算法实例</span></h1>
<p>•<span style="color:#000000;">sklearn20</span><span style="color:#000000;">类新闻分类</span></p>
<p>•<span style="color:#000000;">20</span><span style="color:#000000;">个新闻组数据集包含</span><span style="color:#000000;">20</span><span style="color:#000000;">个主题的</span><span style="color:#000000;">18000</span><span style="color:#000000;">个新闻组帖子</span></p>
<h3 id="%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A1%88%E4%BE%8B%E6%B5%81%E7%A8%8B"><a name="t36"></a><span style="color:#7030a0;">朴素贝叶斯案例流程</span></h3>
<p style="margin-left:0in;"><span style="color:#000000;">1</span><span style="color:#000000;">、加载</span><span style="color:#000000;">20</span><span style="color:#000000;">类新闻数据，并进行分割</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">2</span><span style="color:#000000;">、生成文章特征词</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">3</span><span style="color:#000000;">、朴素贝叶斯</span><span style="color:#000000;">estimator</span><span style="color:#000000;">流程进行预估</span></p>
<pre class="has" name="code"><code class="hljs python"><ol class="hljs-ln" style="width:989px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">naviebayes</span><span class="hljs-params">()</span>:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string"><span class="hljs-string">"""</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    朴素贝叶斯进行文本分类</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    :return: None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    news = fetch_20newsgroups(subset=<span class="hljs-string">'all'</span>)  <span class="hljs-comment"># 获取所有数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行数据分割 news.data：文章，news.target：类别，x：特征值，y：目标值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, test_size=<span class="hljs-number">0.25</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 对数据集进行特征抽取</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    tf = TfidfVectorizer()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 以训练集当中的词的列表进行每篇文章重要性统计['a','b','c','d']</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train = tf.fit_transform(x_train)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(tf.get_feature_names())</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_test = tf.transform(x_test)  <span class="hljs-comment"># 以['a','b','c','d']进行统计测试集的重要性</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行朴素贝叶斯算法的预测</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    mlt = MultinomialNB(alpha=<span class="hljs-number">1.0</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(x_train.toarray())</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    mlt.fit(x_train, y_train)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    y_predict = mlt.predict(x_test)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"预测的文章类别为："</span>, y_predict)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 得出准确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"准确率为："</span>, mlt.score(x_test, y_test))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"每个类别的精确率和召回率："</span>, classification_report(y_test, y_predict, target_names=news.target_names))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> <span class="hljs-keyword">None</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre>
<p style="margin-left:0in;"><img alt="" class="has" height="139" src="https://img-blog.csdnimg.cn/20190708160333986.png" width="813"></p>
<h3 id="%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E4%BC%98%E7%BC%BA%E7%82%B9" style="margin-left:0in;"><a name="t37"></a><span style="color:#7030a0;">朴素贝叶斯分类优缺点</span></h3>
<blockquote>
<p>•<span style="color:#000000;">优点：</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">对缺失数据不太敏感，算法也比较简单，常用于文本分类。</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">分类准确度高，速度快</span></p>
<p>•<span style="color:#000000;">缺点：</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">需要知道</span><span style="color:#ff0000;">先验概率</span><span style="color:#ff0000;">P(F1,F2,</span><span style="color:#ff0000;">…</span><span style="color:#ff0000;">|C)</span><span style="color:#000000;">，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳。</span></p>
<p style="text-indent:0;"><strong><span style="color:#000000;">不需要调参</span></strong></p>
</blockquote>

<h1 id="7%E3%80%81%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%80%89%E6%8B%A9%E4%B8%8E%E8%B0%83%E4%BC%98" style="margin-left:0in;"><a name="t38"></a><span style="color:#000000;">7</span><span style="color:#000000;">、模型的选择与调优</span></h1>
<h3 id="%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E8%BF%87%E7%A8%8B" style="margin-left:0in;"><a name="t39"></a><span style="color:#7030a0;">交叉验证过程</span></h3>
<p><span style="color:#0070c0;">交叉验证：为了让被评估的模型更加准确可信</span></p>
<p><img alt="" class="has" height="330" src="https://img-blog.csdnimg.cn/20190717124028461.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="624"></p>
<h3 id="%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2"><a name="t40"></a><span style="color:#7030a0;">超参数搜索</span><span style="color:#7030a0;">-</span><span style="color:#7030a0;">网格搜索</span></h3>
<p><img alt="" class="has" height="97" src="https://img-blog.csdnimg.cn/20190717124455804.png" width="603"><img alt="" class="has" height="72" src="https://img-blog.csdnimg.cn/20190717124514773.png" width="518"></p>
<h3 id="%E8%B6%85%E5%8F%82%E6%95%B0%E6%90%9C%E7%B4%A2-%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2API"><a name="t41"></a><span style="color:#7030a0;">超参数搜索</span><span style="color:#7030a0;">-</span><span style="color:#7030a0;">网格搜索</span><span style="color:#7030a0;">API</span></h3>
<p>•<span style="color:#000000;">sklearn.model_selection.</span><span style="color:#ff0000;">GridSearchCV</span></p>
<h3 id="GridSearchCV" style="margin-left:0in;"><a name="t42"></a><span style="color:#e46c0a;">GridSearchCV</span></h3>
<blockquote>
<p>•<span style="color:#000000;">sklearn.model_selection.GridSearchCV</span><span style="color:#222222;">(</span><span style="color:#222222;">estimator,&nbsp;param_grid=None</span><span style="color:#222222;">,</span><span style="color:#222222;">cv=None</span><span style="color:#222222;">)</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">对估计器的指定参数值进行详尽搜索</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">estimator</span><span style="color:#000000;">：估计器对象</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">param_grid</span><span style="color:#000000;">：估计器参数</span><span style="color:#000000;">(</span><span style="color:#ff0000;">dict</span><span style="color:#000000;">){“</span><span style="color:#000000;">n_neighbors</span><span style="color:#000000;">”:[1,3,5]}</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">cv</span><span style="color:#000000;">：指定几折交叉验证</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">fit</span><span style="color:#000000;">：输入训练数据</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">score</span><span style="color:#000000;">：准确率</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">结果分析：</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">best_score_:</span><span style="color:#000000;">在交叉验证中测试的最好结果</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">best_estimator_</span><span style="color:#000000;">：最好的参数</span><span style="color:#000000;">模型</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">cv_results_:</span><span style="color:#000000;">每次交叉验证后的测试集准确率结果和训练集</span><span style="color:#000000;">准确率</span><span style="color:#000000;">结果</span></p>
</blockquote>

<p><strong><span style="color:#000000;">将前面的</span><span style="color:#000000;">k-</span><span style="color:#000000;">近邻算法案例改成网格搜索</span></strong>&nbsp;</p>
<pre class="has" name="code"><code class="hljs python"><ol class="hljs-ln" style="width:1068px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">knncls</span><span class="hljs-params">()</span>:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string"><span class="hljs-string">"""</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    K-近邻预测用户签到位置</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    :return:None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 读取数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data = pd.read_csv(<span class="hljs-string">"./data/FBlocation/train.csv"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print(data.head(10))</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 处理数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 1、缩小数据,查询数据筛选</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data = data.query(<span class="hljs-string">"x &gt; 1.0 &amp;  x &lt; 1.25 &amp; y &gt; 2.5 &amp; y &lt; 2.75"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 处理时间的数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    time_value = pd.to_datetime(data[<span class="hljs-string">'time'</span>], unit=<span class="hljs-string">'s'</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(time_value)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 把日期格式转换成 字典格式</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    time_value = pd.DatetimeIndex(time_value)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 构造一些特征</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data[<span class="hljs-string">'day'</span>] = time_value.day</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data[<span class="hljs-string">'hour'</span>] = time_value.hour</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data[<span class="hljs-string">'weekday'</span>] = time_value.weekday</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 把时间戳特征删除</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data = data.drop([<span class="hljs-string">'time'</span>], axis=<span class="hljs-number">1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(data)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 把签到数量少于n个目标位置删除</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    place_count = data.groupby(<span class="hljs-string">'place_id'</span>).count()  <span class="hljs-comment"># 分组统计个数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    tf = place_count[place_count.row_id &gt; <span class="hljs-number">3</span>].reset_index()  <span class="hljs-comment"># 保留了大于3次的数据，reset_index 重置索引，把列属性换成索引</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    data = data[data[<span class="hljs-string">'place_id'</span>].isin(tf.place_id)]  <span class="hljs-comment"># 把tf.place_id在data['place_id']里的数据取出来，即取出大于3次的全部数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 取出数据当中的特征值和目标值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    y = data[<span class="hljs-string">'place_id'</span>]  <span class="hljs-comment"># 目标值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x = data.drop([<span class="hljs-string">'place_id'</span>], axis=<span class="hljs-number">1</span>)  <span class="hljs-comment"># 删除place_id剩下就是特征值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行数据的分割训练集合测试集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="hljs-number">0.25</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 特征工程（标准化：让每一列的数据在同一个标准下进行计算） 不进行标准化时，准确率为2.7%</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    std = StandardScaler()  <span class="hljs-comment"># 训练特征值做标准化，测试特征值也要做标准化，目标值不用做标准化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 对测试集和训练集的特征值进行标准化</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train = std.fit_transform(x_train)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_test = std.transform(x_test)  <span class="hljs-comment"># 不用fit（不用重新计算一次方差，平均值...）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行算法流程 # 超参数</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="57"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    knn = KNeighborsClassifier()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="58"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="59"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># # fit， predict,score</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="60"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># knn.fit(x_train, y_train)  # 输入数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="61"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="62"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># # 得出预测结果</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="63"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># y_predict = knn.predict(x_test)  # 以测试集预测</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="64"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="65"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print("预测的目标签到位置为：", y_predict)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="66"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="67"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># # 得出预测准确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="68"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print("预测的准确率:", knn.score(x_test, y_test))  # 用x_test得出预测值与y_test比较</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="69"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="70"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 构造一些参数的值进行搜索</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="71"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    param = {<span class="hljs-string">"n_neighbors"</span>: [<span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">10</span>]}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="72"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="73"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行网格搜索</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="74"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    gc = GridSearchCV(knn, param_grid=param, cv=<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="75"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="76"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    gc.fit(x_train, y_train)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="77"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="78"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 预测准确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="79"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"在测试集上准确率："</span>, gc.score(x_test, y_test))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="80"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="81"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"在交叉验证当中最好的结果："</span>, gc.best_score_)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="82"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="83"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"选择最好的模型是："</span>, gc.best_estimator_)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="84"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="85"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"每个超参数每次交叉验证的结果："</span>, gc.cv_results_)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="86"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="87"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> <span class="hljs-keyword">None</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre>
<h1 id="8%E3%80%81%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97" style="margin-left:0in;"><a name="t43"></a><span style="color:#000000;">8</span><span style="color:#000000;">、决策树与随机森林</span></h1>
<h2 id="%E5%86%B3%E7%AD%96%E6%A0%91"><a name="t44"></a><span style="color:#000000;">决策树</span></h2>
<h3 id="%E8%AE%A4%E8%AF%86%E5%86%B3%E7%AD%96%E6%A0%91"><a name="t45"></a><span style="color:#7030a0;">认识决策树</span></h3>
<p><span style="color:#000000;">决策树思想的来源非常朴素，程序设计中的条件分支结构就是</span><span style="color:#000000;">if-then</span><span style="color:#000000;">结构，最早的决策树就是利用这类结构分割数据的一种分类学习方法</span></p>
<p><img alt="" class="has" height="216" src="https://img-blog.csdnimg.cn/20190717125818600.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="379"></p>
<h3 id="%E4%BF%A1%E6%81%AF%E7%9A%84%E5%BA%A6%E9%87%8F%E5%92%8C%E4%BD%9C%E7%94%A8" style="margin-left:0in;"><a name="t46"></a><span style="color:#e46c0a;">信息的度量和作用</span></h3>
<p><img alt="" class="has" height="296" src="https://img-blog.csdnimg.cn/20190717130537377.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="507"></p>
<h3 id="%E4%BF%A1%E6%81%AF%E7%86%B5" style="margin-left:0in;"><a name="t47"></a><span style="color:#0070c0;">信息熵</span></h3>
<p><img alt="" class="has" height="95" src="https://img-blog.csdnimg.cn/20190717130603604.png" width="488"><img alt="" class="has" height="162" src="https://img-blog.csdnimg.cn/20190717130621613.png" width="508"></p>
<p><span style="color:#0070c0;">信息和消除不确定性是相联系的</span></p>
<h3 id="%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E5%88%92%E5%88%86%E4%BE%9D%E6%8D%AE%E4%B9%8B%E4%B8%80-%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A"><a name="t48"></a><span style="color:#7030a0;">决策树的划分依据之一</span><span style="color:#7030a0;">-</span><span style="color:#7030a0;">信息增益</span></h3>
<p><img alt="" class="has" height="127" src="https://img-blog.csdnimg.cn/20190717131309723.png" width="543"></p>
<p style="margin-left:0in;"><span style="color:#0070c0;"><strong>注：信息增益表示得知特征</strong></span><span style="color:#0070c0;"><strong>X</strong></span><span style="color:#0070c0;"><strong>的信息而使得类</strong></span><span style="color:#0070c0;"><strong>Y</strong></span><span style="color:#0070c0;"><strong>的信息的不确定性减少的程度</strong></span></p>
<h3 id="%E4%BF%A1%E6%81%AF%E5%A2%9E%E7%9B%8A%E7%9A%84%E8%AE%A1%E7%AE%97" style="margin-left:0in;"><a name="t49"></a><span style="color:#7030a0;">信息增益的计算</span></h3>
<p><img alt="" class="has" height="357" src="https://img-blog.csdnimg.cn/20190717131347322.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="576"><img alt="" class="has" height="366" src="https://img-blog.csdnimg.cn/20190717131617397.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="646"></p>
<p><strong>所以A3作为判定的第一个标准</strong></p>
<p><img alt="" class="has" height="487" src="https://img-blog.csdnimg.cn/20190717131733331.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="776"></p>
<h3 id="%E5%B8%B8%E8%A7%81%E5%86%B3%E7%AD%96%E6%A0%91%E4%BD%BF%E7%94%A8%E7%9A%84%E7%AE%97%E6%B3%95"><a name="t50"></a><span style="color:#7030a0;">常见决策树使用的算法</span></h3>
<blockquote>
<p>•<span style="color:#000000;">ID3</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">信息增益 最大的准则</span></p>
<p>•<span style="color:#000000;">C4.5</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">信息增益比 最大的准则</span></p>
<p>•<span style="color:#000000;">CART </span></p>
<p style="margin-left:0in;"><span style="color:#000000;">回归树</span><span style="color:#000000;">: </span><span style="color:#000000;">平方误差 最小 </span></p>
<p style="margin-left:0in;"><span style="color:#000000;">分类树</span><span style="color:#000000;">: </span><span style="color:#000000;">基尼系数（划分更加仔细）&nbsp; &nbsp;最小的准则 在</span><span style="color:#000000;">sklearn</span><span style="color:#000000;">中可以选择划分的原则</span></p>
</blockquote>

<h3 id="sklearn%E5%86%B3%E7%AD%96%E6%A0%91API" style="margin-left:0in;"><a name="t51"></a><span style="color:#7030a0;">sklearn</span><span style="color:#7030a0;">决策树</span><span style="color:#7030a0;">API</span></h3>
<blockquote>
<p>•<span style="color:#222222;"><em>class&nbsp;</em></span><span style="color:#000000;">sklearn.tree.DecisionTreeClassifier</span><span style="color:#222222;">(</span><span style="color:#222222;"><em>criterion=’</em></span><span style="color:#222222;"><em>gini</em></span><span style="color:#222222;"><em>’</em></span><span style="color:#222222;">,&nbsp;</span><span style="color:#222222;"><em>max_depth</em></span><span style="color:#222222;"><em>=</em></span><span style="color:#222222;"><em>None</em></span><span style="color:#222222;"><em>,</em></span><span style="color:#222222;"><em>random_state</em></span><span style="color:#222222;"><em>=None</em></span><span style="color:#222222;">)</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">决策树分类器</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">criterion:</span><span style="color:#000000;">默认是</span><span style="color:#000000;">’</span><span style="color:#000000;">gini</span><span style="color:#000000;">’</span><span style="color:#000000;">系数，也可以选择信息增益的熵</span><span style="color:#000000;">’entropy’</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">max_depth</span><span style="color:#000000;">:</span><span style="color:#000000;">树的深度大小</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">random_state</span><span style="color:#000000;">:</span><span style="color:#000000;">随机数种子</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">method:</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">decision_path</span><span style="color:#000000;">:</span><span style="color:#000000;">返回决策树的路径</span></p>
</blockquote>

<p style="margin-left:0in;"><span style="color:#000000;"><strong>泰坦尼克号数据</strong></span></p>
<p style="margin-left:0in;"><span style="color:#000000;">在泰坦尼克号和</span><span style="color:#000000;">titanic2</span><span style="color:#000000;">数据帧描述泰坦尼克号上的个别乘客的生存状态。在泰坦尼克号的数据帧不包含从剧组信息，但它确实包含了乘客的一半的实际年龄。关于泰坦尼克号旅客的数据的主要来源是百科全书</span><span style="color:#000000;">Titanica</span><span style="color:#000000;">。这里使用的数据集是由各种研究人员开始的。其中包括许多研究人员创建的旅客名单，由</span><span style="color:#000000;">Michael A. Findlay</span><span style="color:#000000;">编辑。</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">我们提取的数据集中的</span><span style="color:#000000;">特征是票的类别</span><span style="color:#000000;">，存活，</span><span style="color:#000000;">乘坐班</span><span style="color:#000000;">，年龄，登陆，</span><span style="color:#000000;">home.dest</span><span style="color:#000000;">，房间，票，船和性别。</span><span style="color:#ff0000;">乘坐班是指乘客班（</span><span style="color:#ff0000;">1</span><span style="color:#ff0000;">，</span><span style="color:#ff0000;">2</span><span style="color:#ff0000;">，</span><span style="color:#ff0000;">3</span><span style="color:#ff0000;">），是社会经济阶层的代表。</span></p>
<p style="margin-left:0in;"><span style="color:#ff0000;">其中</span><span style="color:#ff0000;">age</span><span style="color:#ff0000;">数据存在缺失。</span></p>
<p style="margin-left:0in;"><img alt="" class="has" height="226" src="https://img-blog.csdnimg.cn/20190717132153924.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="902"></p>
<h3 id="%E6%B3%B0%E5%9D%A6%E5%B0%BC%E5%85%8B%E5%8F%B7%E4%B9%98%E5%AE%A2%E7%94%9F%E5%AD%98%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B" style="margin-left:0in;"><a name="t52"></a><span style="color:#0070c0;">泰坦尼克号乘客生存分类模型</span></h3>
<blockquote>
<p style="margin-left:0in;"><span style="color:#000000;">1</span><span style="color:#000000;">、</span><span style="color:#000000;">pd</span><span style="color:#000000;">读取数据</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">2</span><span style="color:#000000;">、选择有影响的特征，处理缺失值</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">3</span><span style="color:#000000;">、进行特征工程，</span><span style="color:#000000;">pd</span><span style="color:#000000;">转换字典，特征抽取</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">x_train.to_dict</span><span style="color:#000000;">(orient="records")</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">4</span><span style="color:#000000;">、决策树估计器流程</span></p>
</blockquote>

<p>&nbsp;</p>
<h3 id="%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%BB%93%E6%9E%84%E3%80%81%E6%9C%AC%E5%9C%B0%E4%BF%9D%E5%AD%98" style="margin-left:0in;"><a name="t53"></a><span style="color:#7030a0;">决策树的结构、本地保存</span></h3>
<blockquote>
<p style="margin-left:0in;"><span style="color:#000000;">1</span><span style="color:#000000;">、</span><span style="color:#000000;">sklearn.tree.export_graphviz()&nbsp;</span><span style="color:#000000;">该函数能够导出</span><span style="color:#000000;">DOT</span><span style="color:#000000;">格式</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">tree.export_graphviz</span><span style="color:#000000;">(</span><span style="color:#ff0000;">estimator</span><span style="color:#000000;">,out_file</span><span style="color:#000000;">='tree.dot’,</span><span style="color:#000000;">feature_names</span><span style="color:#000000;">=[‘’,’’])</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">2</span><span style="color:#000000;">、工具</span><span style="color:#000000;">:(</span><span style="color:#000000;">能够将</span><span style="color:#000000;">dot</span><span style="color:#000000;">文件转换为</span><span style="color:#000000;">pdf</span><span style="color:#000000;">、</span><span style="color:#000000;">png</span><span style="color:#000000;">)</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">安装</span><span style="color:#ff0000;">graphviz</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">ubuntu:sudo</span><span style="color:#000000;"> apt-get install </span><span style="color:#000000;">graphviz</span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <span style="color:#000000;">Mac:brew</span><span style="color:#000000;"> install </span><span style="color:#000000;">graphviz</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">3</span><span style="color:#000000;">、运行命令</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">然后我们运行这个命令</span></p>
<p style="margin-left:0in;"><span style="color:#ff0000;">$ dot -</span><span style="color:#ff0000;">Tpng</span><span style="color:#ff0000;"> tree.dot -o tree.png</span></p>
</blockquote>

<p>&nbsp;效果图：</p>
<p><img alt="" class="has" src="https://img-blog.csdnimg.cn/20190717134716225.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70"></p>
<pre class="has" name="code"><code class="hljs python"><ol class="hljs-ln" style="width:1144px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">decision</span><span class="hljs-params">()</span>:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string"><span class="hljs-string">"""</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    决策树对泰坦尼克号进行预测生死</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    :return: None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 获取数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    titan = pd.read_csv(<span class="hljs-string">"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 处理数据，找出特征值和目标值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x = titan[[<span class="hljs-string">'pclass'</span>, <span class="hljs-string">'age'</span>, <span class="hljs-string">'sex'</span>]]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    y = titan[<span class="hljs-string">'survived'</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 缺失值处理</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x[<span class="hljs-string">'age'</span>].fillna(x[<span class="hljs-string">'age'</span>].mean(), inplace=<span class="hljs-keyword">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 分割数据集到训练集合测试集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="hljs-number">0.25</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行处理（特征工程）特征-》类别-》one_hot编码</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    dict = DictVectorizer(sparse=<span class="hljs-keyword">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train = dict.fit_transform(x_train.to_dict(orient=<span class="hljs-string">"records"</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(dict.get_feature_names())</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_test = dict.transform(x_test.to_dict(orient=<span class="hljs-string">"records"</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print(x_train)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 用决策树进行预测</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    dec = DecisionTreeClassifier()</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    dec.fit(x_train, y_train)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 预测准确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"预测的准确率："</span>, dec.score(x_test, y_test))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 导出决策树的结构</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    export_graphviz(dec, out_file=<span class="hljs-string">"./tree.dot"</span>, feature_names=[<span class="hljs-string">'年龄'</span>, <span class="hljs-string">'pclass=1st'</span>, <span class="hljs-string">'pclass=2nd'</span>, <span class="hljs-string">'pclass=3rd'</span>, <span class="hljs-string">'女性'</span>, <span class="hljs-string">'男性'</span>])</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> <span class="hljs-keyword">None</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre>
<h3 id="%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%E4%BB%A5%E5%8F%8A%E6%94%B9%E8%BF%9B"><a name="t54"></a><span style="color:#7030a0;">决策树的优缺点以及改进</span></h3>
<blockquote>
<p>•<span style="color:#000000;">优点：</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">简单的理解和解释，树木可视化。</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">需要很少的数据准备，其他技术通常需要数据归一化，</span></p>
<p>•<span style="color:#000000;">缺点：</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">决策树学习者可以创建不能很好地推广数据的过于复杂的树，这被称为过拟合。</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">决策树可能不稳定，因为数据的小变化可能会导致完全不同的树被生成</span></p>
<p>•<span style="color:#000000;">改进：</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">减枝</span><span style="color:#000000;">cart</span><span style="color:#000000;">算法</span></p>
<p style="text-indent:50px;">•<span style="color:#ff0000;">随机森林</span></p>
</blockquote>

<h2 id="%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><a name="t55"></a>随机森林</h2>
<h3 id="%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><a name="t56"></a><span style="color:#0070c0;">集成学习方法</span><span style="color:#0070c0;">-</span><span style="color:#0070c0;">随机森林</span></h3>
<blockquote>
<p><span style="color:#ff0000;">集成学习方法</span></p>

<p><span style="color:#000000;">　　集成学习通过建立几个模型组合的来解决单一预测问题。它的工作原理是</span><span style="color:#ff0000;">生成多个分类器</span><span style="color:#ff0000;">/</span><span style="color:#ff0000;">模型</span><span style="color:#000000;">，各自独立地学习和作出预测。这些预测最后结合成单预测，因此优于任何一个单分类的做出预测。</span></p>
</blockquote>

<h3 id="%E4%BB%80%E4%B9%88%E6%98%AF%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><a name="t57"></a><span style="color:#7030a0;">什么是随机森林</span></h3>
<blockquote>
<p><span style="color:#222222;">定义：在机器学习中</span><span style="color:#222222;">，</span><span style="color:#222222;"><strong>随机森林</strong></span><span style="color:#222222;">是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定。</span></p>
</blockquote>

<p><span style="color:#333333;">例如</span><span style="color:#333333;">, </span><span style="color:#333333;">如果你训练了</span><span style="color:#333333;">5</span><span style="color:#333333;">个树</span><span style="color:#333333;">, </span><span style="color:#333333;">其中有</span><span style="color:#333333;">4</span><span style="color:#333333;">个树的结果是</span><span style="color:#333333;">True, 1</span><span style="color:#333333;">个数的结果是</span><span style="color:#333333;">False, </span><span style="color:#333333;">那么最终结果会是</span><span style="color:#333333;">True.</span></p>
<p style="margin-left:0in;"><span style="color:#333333;"><strong>学习算法</strong></span></p>
<p style="margin-left:0in;"><span style="color:#333333;">根据下列算法而建造每棵树：</span></p>
<p>•<span style="color:#333333;">用</span><span style="color:#333333;">N</span><span style="color:#333333;">来表示训练用例（样本）的个数，</span><span style="color:#333333;">M</span><span style="color:#333333;">表示特征数目。</span></p>
<p>•<span style="color:#333333;">输入特征数目</span><span style="color:#333333;">m</span><span style="color:#333333;">，用于确定决策树上一个节点的决策结果；其中</span><span style="color:#333333;">m</span><span style="color:#333333;">应远小于</span><span style="color:#333333;">M</span><span style="color:#333333;">。</span></p>
<p>•<span style="color:#333333;">从</span><span style="color:#333333;">N</span><span style="color:#333333;">个训练用例（样本）中以</span><span style="color:#ff0000;">有放回抽样</span><span style="color:#333333;">的方式，取样</span><span style="color:#333333;">N</span><span style="color:#333333;">次，形成一个训练集（即</span><span style="color:#333333;">bootstrap</span><span style="color:#333333;">取样），并用未抽到的用例（样本）作预测，评估其误差。</span></p>
<blockquote>
<p>•<span style="color:#ff0000;"><strong>为什么要随机抽样训练集？</strong></span>　　</p>

<p style="margin-left:0in;"><span style="color:#000000;">如果不进行随机抽样，每棵树的训练集都一样，那么最终训练出的树分类结果也是完全一样</span><span style="color:#000000;">的</span></p>
<p>•<span style="color:#ff0000;"><strong>为什么要有放回地抽样？</strong></span></p>
<p style="margin-left:0in;"><span style="color:#000000;">　　如果不是有放回的抽样，那么每棵树的训练样本都是不同的，都是没有交集的，这样每棵树都是</span><span style="color:#000000;">“</span><span style="color:#000000;">有偏的</span><span style="color:#000000;">”</span><span style="color:#000000;">，都是绝对</span><span style="color:#000000;">“</span><span style="color:#000000;">片面的</span><span style="color:#000000;">”</span><span style="color:#000000;">（当然这样说可能不对），也就是说每棵树训练出来都是有很大的差异的；而随机森林最后分类取决于多棵树（弱分类器）的投票表决。</span></p>
</blockquote>

<h3 id="%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97API" style="margin-left:0in;"><a name="t58"></a><span style="color:#7030a0;">随机森林</span><span style="color:#7030a0;">API</span></h3>
<p><img alt="" class="has" height="342" src="https://img-blog.csdnimg.cn/20190717202730635.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="755"></p>
<pre class="has" name="code"><code class="hljs python"><ol class="hljs-ln" style="width:1161px"><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="1"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">decision</span><span class="hljs-params">()</span>:</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="2"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-string"><span class="hljs-string">"""</span></span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="3"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    决策树对泰坦尼克号进行预测生死</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="4"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    :return: None</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="5"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"><span class="hljs-string">    """</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="6"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 获取数据</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="7"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    titan = pd.read_csv(<span class="hljs-string">"http://biostat.mc.vanderbilt.edu/wiki/pub/Main/DataSets/titanic.txt"</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="8"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="9"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 处理数据，找出特征值和目标值</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="10"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x = titan[[<span class="hljs-string">'pclass'</span>, <span class="hljs-string">'age'</span>, <span class="hljs-string">'sex'</span>]]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="11"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="12"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    y = titan[<span class="hljs-string">'survived'</span>]</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="13"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="14"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(x)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="15"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 缺失值处理</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="16"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x[<span class="hljs-string">'age'</span>].fillna(x[<span class="hljs-string">'age'</span>].mean(), inplace=<span class="hljs-keyword">True</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="17"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="18"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 分割数据集到训练集合测试集</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="19"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=<span class="hljs-number">0.25</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="20"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="21"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 进行处理（特征工程）特征-》类别-》one_hot编码</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="22"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    dict = DictVectorizer(sparse=<span class="hljs-keyword">False</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="23"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="24"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_train = dict.fit_transform(x_train.to_dict(orient=<span class="hljs-string">"records"</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="25"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="26"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(dict.get_feature_names())</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="27"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="28"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    x_test = dict.transform(x_test.to_dict(orient=<span class="hljs-string">"records"</span>))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="29"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="30"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print(x_train)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="31"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 用决策树进行预测</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="32"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># dec = DecisionTreeClassifier()</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="33"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="34"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># dec.fit(x_train, y_train)</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="35"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="36"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># # 预测准确率</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="37"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># print("预测的准确率：", dec.score(x_test, y_test))</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="38"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment">#</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="39"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># # 导出决策树的结构</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="40"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># export_graphviz(dec, out_file="./tree.dot", feature_names=['年龄', 'pclass=1st', 'pclass=2nd', 'pclass=3rd', '女性', '男性'])</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="41"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="42"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 随机森林进行预测 （超参数调优）</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="43"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    rf = RandomForestClassifier(n_jobs=<span class="hljs-number">-1</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="44"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="45"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    param = {<span class="hljs-string">"n_estimators"</span>: [<span class="hljs-number">120</span>, <span class="hljs-number">200</span>, <span class="hljs-number">300</span>, <span class="hljs-number">500</span>, <span class="hljs-number">800</span>, <span class="hljs-number">1200</span>], <span class="hljs-string">"max_depth"</span>: [<span class="hljs-number">5</span>, <span class="hljs-number">8</span>, <span class="hljs-number">15</span>, <span class="hljs-number">25</span>, <span class="hljs-number">30</span>]}</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="46"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="47"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-comment"># 网格搜索与交叉验证</span></div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="48"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    gc = GridSearchCV(rf, param_grid=param, cv=<span class="hljs-number">2</span>)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="49"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="50"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    gc.fit(x_train, y_train)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="51"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="52"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"准确率："</span>, gc.score(x_test, y_test))</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="53"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="54"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    print(<span class="hljs-string">"查看选择的参数模型："</span>, gc.best_params_)</div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="55"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line"> </div></div></li><li><div class="hljs-ln-numbers"><div class="hljs-ln-line hljs-ln-n" data-line-number="56"></div></div><div class="hljs-ln-code"><div class="hljs-ln-line">    <span class="hljs-keyword">return</span> <span class="hljs-keyword">None</span></div></div></li></ol></code><div class="hljs-button {2}" data-title="复制" onclick="hljs.copyCode(event)"></div></pre>
<h3 id="%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E4%BC%98%E7%82%B9" style="margin-left:0in;"><a name="t59"></a><span style="color:#7030a0;">随机森林的优点</span></h3>
<blockquote>
<p>•<span style="color:#000000;">在当前所有算法中，具有极好的准确率</span></p>

<p>•<span style="color:#000000;">能够有效地运行在大数据集上</span></p>
<p>•<span style="color:#000000;">能够处理具有高维特征的输入样本，而且不需要降维</span></p>
<p>•<span style="color:#000000;">能够评估各个特征在分类问题上的重要性</span></p>
<p>•<span style="color:#000000;">对于缺省值问题也能够获得很好得结果</span></p>