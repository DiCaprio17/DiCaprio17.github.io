---
layout:     post
title:      机器学习—学习笔记#day03
subtitle:   机器学习
date:       2019-07-24
author:     DiCaprio
header-img: img/post-bg-spring.jpeg
catalog: true
tags:
    - 机器学习
    - Python
---

<p id="main-toc"><strong>目录</strong></p>

<p id="%E6%80%BB%E7%BB%93-toc" style="margin-left:0px;"><a href="#%E6%80%BB%E7%BB%93" rel="nofollow" data-token="6582eb50fd7f3eb4e88727028ec806ef" target="_self">总结</a></p>
<p id="1%E3%80%81%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90-toc" style="margin-left:0px;"><a href="#1%E3%80%81%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90" rel="nofollow" data-token="463a0d3b19c4ca7bae8bcf3ebba9a5d1" target="_self">1、回归算法-线性回归分析</a></p>
<p id="%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B-toc" style="margin-left:40px;"><a href="#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B" rel="nofollow" data-token="8e8e31ace5461586be95dd9296358b0c" target="_self">线性模型</a></p>
<p id="%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-toc" style="margin-left:40px;"><a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" rel="nofollow" data-token="6fe69f3c41d9ea5d6797320d7506d5bb" target="_self">线性回归</a></p>
<p id="%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0(%E8%AF%AF%E5%B7%AE%E5%A4%A7%E5%B0%8F)-toc" style="margin-left:40px;"><a href="#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0(%E8%AF%AF%E5%B7%AE%E5%A4%A7%E5%B0%8F)" rel="nofollow" data-token="fe560eca7b939c4efabec05a1d824fd5" target="_self">损失函数(误差大小)</a></p>
<p id="%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E4%B9%8B%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B(%E4%B8%8D%E5%81%9A%E8%A6%81%E6%B1%82)-toc" style="margin-left:40px;"><a href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E4%B9%8B%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B(%E4%B8%8D%E5%81%9A%E8%A6%81%E6%B1%82)" rel="nofollow" data-token="4ebbbd773971b7890ca735f0820313e2" target="_self">最小二乘法之正规方程(不做要求)</a></p>
<p id="%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E4%B9%8B%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D(%E7%90%86%E8%A7%A3%E8%BF%87%E7%A8%8B)-toc" style="margin-left:40px;"><a href="#%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E4%B9%8B%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D(%E7%90%86%E8%A7%A3%E8%BF%87%E7%A8%8B)" rel="nofollow" data-token="bb7deaf9dd1d170a1c1fedd0b225d11a" target="_self">最小二乘法之梯度下降(理解过程)</a></p>
<p id="sklearn%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E3%80%81%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8DAPI-toc" style="margin-left:40px;"><a href="#sklearn%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E3%80%81%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8DAPI" rel="nofollow" data-token="49c772cbaed36d9c9ce196c6a7349b0a" target="_self">sklearn线性回归正规方程、梯度下降API</a></p>
<p id="LinearRegression%E3%80%81SGDRegressor-toc" style="margin-left:80px;"><a href="#LinearRegression%E3%80%81SGDRegressor" rel="nofollow" data-token="e13fe408a7d7d79b748c5fbe2243509a" target="_self">LinearRegression、SGDRegressor</a></p>
<p id="2%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E4%BE%8B-toc" style="margin-left:0px;"><a href="#2%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E4%BE%8B" rel="nofollow" data-token="337d6b8d25457839f12abda19c1a433a" target="_self">2、线性回归实例</a></p>
<p id="%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B-toc" style="margin-left:40px;"><a href="#%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B" rel="nofollow" data-token="c14e1878eb6a787fa65da670fdbce96f" target="_self">波士顿房价数据案例分析流程</a></p>
<p id="3%E3%80%81%E5%9B%9E%E5%BD%92%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0-toc" style="margin-left:0px;"><a href="#3%E3%80%81%E5%9B%9E%E5%BD%92%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0" rel="nofollow" data-token="f050d2f0c742bd098dd38053a44af49f" target="_self">3、回归性能评估</a></p>
<p id="sklearn%E5%9B%9E%E5%BD%92%E8%AF%84%E4%BC%B0API-toc" style="margin-left:40px;"><a href="#sklearn%E5%9B%9E%E5%BD%92%E8%AF%84%E4%BC%B0API" rel="nofollow" data-token="28a68f7d183f5b01b289e9ac53d62ab4" target="_self">sklearn回归评估API</a></p>
<p id="mean_squared_error-toc" style="margin-left:80px;"><a href="#mean_squared_error" rel="nofollow" data-token="19160365f0518a1fcbb8a0b190d881e4" target="_self">mean_squared_error</a></p>
<p id="%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88-toc" style="margin-left:40px;"><a href="#%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88" rel="nofollow" data-token="1cb095907473ca3f210e3c8f0d8489c1" target="_self">过拟合与欠拟合</a></p>
<p id="%E6%AC%A0%E6%8B%9F%E5%90%88%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95-toc" style="margin-left:40px;"><a href="#%E6%AC%A0%E6%8B%9F%E5%90%88%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95" rel="nofollow" data-token="aef875364568a574de34e7b172103e68" target="_self">欠拟合原因以及解决办法</a></p>
<p id="%E8%BF%87%E6%8B%9F%E5%90%88%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95-toc" style="margin-left:40px;"><a href="#%E8%BF%87%E6%8B%9F%E5%90%88%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95" rel="nofollow" data-token="8eae666dd3d4feac180aba2c1fbcf3ab" target="_self">过拟合原因以及解决办法</a></p>
<p id="L2%E6%AD%A3%E5%88%99%E5%8C%96-toc" style="margin-left:40px;"><a href="#L2%E6%AD%A3%E5%88%99%E5%8C%96" rel="nofollow" data-token="d245105df44dc2fd29705127d9419806" target="_self">L2正则化</a></p>
<p id="%E5%B8%A6%E6%9C%89%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-Ridge-toc" style="margin-left:40px;"><a href="#%E5%B8%A6%E6%9C%89%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-Ridge" rel="nofollow" data-token="d5676c2f0a84ae32ea7d941ce6e37bb2" target="_self">带有正则化的线性回归-Ridge</a></p>
<p id="Ridge-toc" style="margin-left:40px;"><a href="#Ridge" rel="nofollow" data-token="142f38e3d2661f678d8830780a74a809" target="_self">Ridge</a></p>
<p id="%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%20LinearRegression%E4%B8%8ERidge%E5%AF%B9%E6%AF%94-toc" style="margin-left:40px;"><a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%20LinearRegression%E4%B8%8ERidge%E5%AF%B9%E6%AF%94" rel="nofollow" data-token="aa9baf03cc08194d9f74705cba1d2a31" target="_self">线性回归 LinearRegression与Ridge对比</a></p>
<p id="sklearn%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E6%8C%81%E5%92%8C%E5%8A%A0%E8%BD%BD-toc" style="margin-left:40px;"><a href="#sklearn%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E6%8C%81%E5%92%8C%E5%8A%A0%E8%BD%BD" rel="nofollow" data-token="e8f654632b35199f426091ef54e6d4ee" target="_self">sklearn模型的保持和加载</a></p>
<p id="%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BDAPI-toc" style="margin-left:80px;"><a href="#%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BDAPI" rel="nofollow" data-token="dd679f6194b183e93855f28fa644b804" target="_self">保存和加载API</a></p>
<p id="4%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-toc" style="margin-left:0px;"><a href="#4%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92" rel="nofollow" data-token="cf5e9f97351bd52bd35c2a9c9f33190b" target="_self">4、分类算法-逻辑回归</a></p>
<p id="%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92-toc" style="margin-left:40px;"><a href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92" rel="nofollow" data-token="0269999f5b41d99ecdae7991bd377357" target="_self">逻辑回归</a></p>
<p id="sigmoid%E5%87%BD%E6%95%B0-toc" style="margin-left:40px;"><a href="#sigmoid%E5%87%BD%E6%95%B0" rel="nofollow" data-token="a7ce70b1d34e025f9e669620041aa5fb" target="_self">sigmoid函数</a></p>
<p id="%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%85%AC%E5%BC%8F-toc" style="margin-left:40px;"><a href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%85%AC%E5%BC%8F" rel="nofollow" data-token="ffbd96cb97c7e182f5bfe54cee965523" target="_self">逻辑回归公式</a></p>
<p id="%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E3%80%81%E4%BC%98%E5%8C%96(%E4%BA%86%E8%A7%A3)-toc" style="margin-left:40px;"><a href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E3%80%81%E4%BC%98%E5%8C%96(%E4%BA%86%E8%A7%A3)" rel="nofollow" data-token="7644126cfdd706955a7ba4377226b374" target="_self">逻辑回归的损失函数、优化(了解)</a></p>
<p id="sklearn%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92API-toc" style="margin-left:40px;"><a href="#sklearn%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92API" rel="nofollow" data-token="420aadfbf98a2729dc99092cde876fef" target="_self">sklearn逻辑回归API</a></p>
<p id="LogisticRegression-toc" style="margin-left:40px;"><a href="#LogisticRegression" rel="nofollow" data-token="75b58e84567d1b9c8bbd0dd1fce0895d" target="_self">LogisticRegression</a></p>
<p id="LogisticRegression%E6%80%BB%E7%BB%93-toc" style="margin-left:40px;"><a href="#LogisticRegression%E6%80%BB%E7%BB%93" rel="nofollow" data-token="d8b596cb532633037422c9a61cc2bbf3" target="_self">LogisticRegression总结</a></p>
<p id="5%E3%80%81%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-kmeans-toc" style="margin-left:0px;"><a href="#5%E3%80%81%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-kmeans" rel="nofollow" data-token="e507962e42eeb76d2524c2dd0cff2d92" target="_self">5、聚类算法-kmeans</a></p>
<p id="%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0(unsupervised%20learning)-toc" style="margin-left:40px;"><a href="#%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0(unsupervised%20learning)" rel="nofollow" data-token="23d3ee05e06695af0a1da11a5e5cb2be" target="_self">非监督学习(unsupervised learning)</a></p>
<p id="k-means%E6%AD%A5%E9%AA%A4-toc" style="margin-left:40px;"><a href="#k-means%E6%AD%A5%E9%AA%A4" rel="nofollow" data-token="ea83fcf9d4af646a5ea66ec4936794d2" target="_self">k-means步骤</a></p>
<p id="k-means%20API-toc" style="margin-left:40px;"><a href="#k-means%20API" rel="nofollow" data-token="d7d625fdc82efd41e72989b9a1c749b3" target="_self">k-means API</a></p>
<p id="Kmeans-toc" style="margin-left:40px;"><a href="#Kmeans" rel="nofollow" data-token="99d6563f0686b5d08fae13420d6159a6" target="_self">Kmeans</a></p>
<p id="k-means%E5%AF%B9Instacart%20Market%E7%94%A8%E6%88%B7%E8%81%9A%E7%B1%BB-toc" style="margin-left:40px;"><a href="#k-means%E5%AF%B9Instacart%20Market%E7%94%A8%E6%88%B7%E8%81%9A%E7%B1%BB" rel="nofollow" data-token="73ea417be4df4e02755a5c30d8a5b31a" target="_self">k-means对Instacart Market用户聚类</a></p>
<p id="Kmeans%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87-toc" style="margin-left:40px;"><a href="#Kmeans%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87" rel="nofollow" data-token="6ca7d1dfe80556d98ff39ffb1b538066" target="_self">Kmeans性能评估指标</a></p>
<hr id="hr-toc"><h1 id="%E6%80%BB%E7%BB%93" style="margin-left:0in;"><a name="t0"></a>总结</h1>

<p><img alt="" class="has" src="https://img-blog.csdnimg.cn/20190722120250943.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70"></p>
<h1 id="1%E3%80%81%E5%9B%9E%E5%BD%92%E7%AE%97%E6%B3%95-%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90" style="margin-left:0in;"><a name="t1"></a><span style="color:#000000;">1</span><span style="color:#000000;">、回归算法</span><span style="color:#000000;">-</span><span style="color:#000000;">线性回归分析</span></h1>
<h2 id="%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B" style="margin-left:0in;"><a name="t2"></a><span style="color:#7030a0;">线性模型</span></h2>
<p><img alt="" class="has" height="125" src="https://img-blog.csdnimg.cn/20190719114851216.png" width="463"></p>
<h2 id="%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92" style="margin-left:0in;"><a name="t3"></a><span style="color:#7030a0;">线性回归</span></h2>
<p><img alt="" class="has" height="301" src="https://img-blog.csdnimg.cn/20190719114912899.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="456"></p>
<p><span style="color:#7030a0;">自变量：特征值&nbsp; &nbsp; 因变量：目标值</span></p>
<p><img alt="" class="has" height="207" src="https://img-blog.csdnimg.cn/20190719115003877.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="311"><img alt="" class="has" height="206" src="https://img-blog.csdnimg.cn/20190719115018872.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="270"></p>
<h2 id="%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0(%E8%AF%AF%E5%B7%AE%E5%A4%A7%E5%B0%8F)" style="margin-left:0in;"><a name="t4"></a><span style="color:#7030a0;">损失函数</span><span style="color:#7030a0;">(</span><span style="color:#7030a0;">误差大小</span><span style="color:#7030a0;">)</span></h2>
<p><img alt="" class="has" height="264" src="https://img-blog.csdnimg.cn/20190719120720786.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="570"></p>
<p style="margin-left:0in;"><strong><span style="color:#000000;">如何去求模型当中的</span><span style="color:#000000;">W</span><span style="color:#000000;">，使得损失最小？</span></strong></p>
<p style="margin-left:0in;"><span style="color:#000000;">（</span><span style="color:#ff0000;">目的是找到最小损失对应的</span><span style="color:#ff0000;">W</span><span style="color:#ff0000;">值</span><span style="color:#000000;">）</span></p>
<h2 id="%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E4%B9%8B%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B(%E4%B8%8D%E5%81%9A%E8%A6%81%E6%B1%82)" style="margin-left:0in;"><a name="t5"></a><span style="color:#7030a0;">最小二乘法之正规方程</span><span style="color:#7030a0;">(</span><span style="color:#7030a0;">不做要求</span><span style="color:#7030a0;">)</span></h2>
<p style="margin-left:0in;"><img alt="" class="has" height="56" src="https://img-blog.csdnimg.cn/20190722110059785.png" width="293"></p>
<p style="margin-left:0in;"><span style="color:#ff0000;">缺点：当特征过于复杂，求解速度太慢</span></p>
<p style="margin-left:0in;"><span style="color:#ff0000;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 对于复杂的算法，不能使用正规方程求解</span><span style="color:#ff0000;">(</span><span style="color:#ff0000;">逻辑回归等</span><span style="color:#ff0000;">)</span></p>
<p style="margin-left:0in;"><img alt="" class="has" height="461" src="https://img-blog.csdnimg.cn/20190722110121900.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="618"></p>
<h2 id="%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E4%B9%8B%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D(%E7%90%86%E8%A7%A3%E8%BF%87%E7%A8%8B)" style="margin-left:0in;"><a name="t6"></a><span style="color:#7030a0;">最小二乘法之梯度下降</span><span style="color:#7030a0;">(</span><span style="color:#7030a0;">理解过程</span><span style="color:#7030a0;">)</span></h2>
<p><img alt="" class="has" height="346" src="https://img-blog.csdnimg.cn/20190722110137175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="619"></p>
<p><span style="color:#7030a0;"><strong>向损失最小的方向，找损失最小的时候</strong></span></p>
<p><img alt="" class="has" height="364" src="https://img-blog.csdnimg.cn/20190722110243689.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="541"></p>
<h2 id="sklearn%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B%E3%80%81%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8DAPI"><a name="t7"></a><span style="color:#7030a0;">sklearn</span><span style="color:#7030a0;">线性回归正规方程、梯度下降</span><span style="color:#7030a0;">API</span></h2>
<blockquote>
<p>•<span style="color:#000000;">sklearn.linear_model.</span><span style="color:#ff0000;">LinearRegression</span></p>

<p style="text-indent:50px;">•<span style="color:#ff0000;">正规方程</span></p>
<p>•<span style="color:#000000;">sklearn.linear_model.</span><span style="color:#ff0000;">SGDRegressor</span></p>
<p style="text-indent:50px;">•<span style="color:#ff0000;">梯度下降</span></p>
</blockquote>

<h3 id="LinearRegression%E3%80%81SGDRegressor" style="margin-left:0in;"><a name="t8"></a><span style="color:#e46c0a;">LinearRegression</span><span style="color:#e46c0a;">、</span><span style="color:#e46c0a;">SGDRegressor</span></h3>
<blockquote>
<p>•<span style="color:#000000;">sklearn.linear_model.LinearRegression</span><span style="color:#000000;">()</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">普通最小二乘线性回归</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">coef</span><span style="color:#000000;">_</span><span style="color:#000000;">：回归系数</span></p>
<p>•<span style="color:#000000;">sklearn.linear_model.SGDRegressor</span><span style="color:#000000;">(</span> <span style="color:#000000;">)</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">通过使用</span><span style="color:#000000;">SGD</span><span style="color:#000000;">最小化线性模型</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">coef</span><span style="color:#000000;">_</span><span style="color:#000000;">：回归系数</span></p>
</blockquote>

<h1 id="2%E3%80%81%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E5%AE%9E%E4%BE%8B" style="margin-left:0in;"><a name="t9"></a><span style="color:#000000;">2</span><span style="color:#000000;">、线性回归实例</span></h1>
<h2 id="%E6%B3%A2%E5%A3%AB%E9%A1%BF%E6%88%BF%E4%BB%B7%E6%95%B0%E6%8D%AE%E6%A1%88%E4%BE%8B%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B" style="margin-left:0in;"><a name="t10"></a><span style="color:#7030a0;">波士顿房价数据案例分析流程</span></h2>
<blockquote>
<p><span style="color:#000000;">1、波士顿地区房价数据获取</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">2</span><span style="color:#000000;">、</span><span style="color:#000000;">波士顿地区房价数据分割</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">3</span><span style="color:#000000;">、</span><span style="color:#ff0000;">训练与测试数据标准化处理</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">4</span><span style="color:#000000;">、</span><span style="color:#000000;">使用最简单的线性回归模型</span><span style="color:#000000;">LinearRegression</span><span style="color:#000000;">和梯度下降估计SGDRegressor</span><span style="color:#000000;">对房价进行预测</span></p>
</blockquote>

<h1 id="3%E3%80%81%E5%9B%9E%E5%BD%92%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0" style="margin-left:0in;"><a name="t11"></a><span style="color:#000000;">3</span><span style="color:#000000;">、回归性能评估</span></h1>
<p><img alt="" class="has" height="176" src="https://img-blog.csdnimg.cn/20190722110949120.png" width="524"></p>
<h2 id="sklearn%E5%9B%9E%E5%BD%92%E8%AF%84%E4%BC%B0API" style="margin-left:0in;"><a name="t12"></a><span style="color:#0070c0;">sklearn</span><span style="color:#0070c0;">回归评估</span><span style="color:#0070c0;">API</span></h2>
<p>•<span style="color:#000000;">sklearn.metrics.</span><span style="color:#ff0000;">mean_squared_error</span></p>
<h3 id="mean_squared_error"><a name="t13"></a><span style="color:#e46c0a;">mean_squared_error</span></h3>
<blockquote>
<p>•<span style="color:#000000;">mean_squared_error</span><span style="color:#222222;">(</span><span style="color:#222222;"><em>y_true</em></span><span style="color:#222222;">,&nbsp;</span><span style="color:#222222;"><em>y_pred</em></span><span style="color:#222222;">)</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">均方误差回归损失</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">y_true</span><span style="color:#000000;">:</span><span style="color:#000000;">真实值</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">y_pred</span><span style="color:#000000;">:</span><span style="color:#000000;">预测值</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">return:</span><span style="color:#000000;">浮点数结果</span></p>
<p style="text-indent:0;"><span style="color:#ff0000;">注：真实值，预测值为标准化之前的值</span></p>
</blockquote>

<p><img alt="" class="has" height="436" src="https://img-blog.csdnimg.cn/20190722112917834.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="847"></p>
<blockquote>
<p style="margin-left:0in;"><span style="color:#000000;">1</span><span style="color:#000000;">、</span><span style="color:#000000;">LinearRegression</span><span style="color:#000000;">与</span><span style="color:#000000;">SGDRegressor</span><span style="color:#000000;">评估</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">2</span><span style="color:#000000;">、特点：线性回归器是最为简单、易用的回归模型。</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">从某种程度上限制了使用，尽管如此，在不知道特征之间关系的前提下，我们仍然使用线性回归器作为大多数系统的首要选择。</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">小规模数据：</span><span style="color:#000000;">LinearRegression</span><span style="color:#000000;">(</span><span style="color:#000000;">不能</span><span style="color:#ff0000;">解决拟合问题</span><span style="color:#ff0000;">)</span><span style="color:#ff0000;">以及其它</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">大规模数据：</span><span style="color:#000000;">SGDRegressor</span></p>
</blockquote>

<h2 id="%E8%BF%87%E6%8B%9F%E5%90%88%E4%B8%8E%E6%AC%A0%E6%8B%9F%E5%90%88" style="margin-left:0in;"><a name="t14"></a><span style="color:#ff0000;">过拟合与欠拟合</span></h2>
<p><img alt="" class="has" height="332" src="https://img-blog.csdnimg.cn/20190722113113936.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="669"></p>
<blockquote>
<p style="margin-left:0in;"><span style="color:#000000;"><strong>过拟合：</strong></span><span style="color:#000000;">一个假设</span><span style="color:#ff0000;">在训练数据上能够获得比其他假设更好的拟合， </span><span style="color:#000000;">但是在</span><span style="color:#ff0000;">训练数据外的数据集上却不能很好地拟合数据</span><span style="color:#000000;">，此时认为这个假设出现了过拟合的现象。</span><span style="color:#000000;">(</span><span style="color:#000000;">模型过于复杂</span><span style="color:#000000;">)</span></p>

<p style="margin-left:0in;"><span style="color:#000000;"><strong>欠拟合：</strong></span><span style="color:#000000;">一个假设</span><span style="color:#ff0000;">在训练数据上不能获得更好的拟合， </span><span style="color:#000000;">在</span><span style="color:#ff0000;">训练数据外的数据集上也不能很好地拟合数据</span><span style="color:#000000;">，此时认为这个假设出现了欠拟合的现象。</span><span style="color:#000000;">(</span><span style="color:#000000;">模型过于简单</span><span style="color:#000000;">)</span></p>
</blockquote>

<h2 id="%E6%AC%A0%E6%8B%9F%E5%90%88%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95" style="margin-left:0in;"><a name="t15"></a><span style="color:#ff0000;">欠拟合原因以及解决办法</span></h2>
<blockquote>
<p>•<span style="color:#000000;">原因：</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">学习到数据的特征过少</span></p>
<p>•<span style="color:#000000;">解决办法：</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">增加数据的特征数量</span></p>
</blockquote>

<h2 id="%E8%BF%87%E6%8B%9F%E5%90%88%E5%8E%9F%E5%9B%A0%E4%BB%A5%E5%8F%8A%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95" style="margin-left:0in;"><a name="t16"></a><span style="color:#ff0000;">过拟合原因以及解决办法</span></h2>
<blockquote>
<p>•<span style="color:#000000;">原因：</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">原始特征过多，存在一些嘈杂特征，</span>&nbsp;<span style="color:#000000;">模型过于复杂是因为模型尝试去兼顾各个测试数据点</span></p>
<p>•<span style="color:#000000;">解决办法：</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">进行特征选择，消除关联性大的特征</span><span style="color:#000000;">(</span><span style="color:#000000;">很难做</span><span style="color:#000000;">)</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">交叉验证</span><span style="color:#000000;">(</span><span style="color:#000000;">让所有数据都有过训练</span><span style="color:#000000;">)</span></p>
<p style="text-indent:50px;">•<strong><span style="color:#000000;">正则化</span></strong><span style="color:#000000;">(</span><span style="color:#000000;">了解</span><span style="color:#000000;">)</span></p>
</blockquote>

<h2 id="L2%E6%AD%A3%E5%88%99%E5%8C%96"><a name="t17"></a><span style="color:#7030a0;">L2</span><span style="color:#7030a0;">正则化</span></h2>
<blockquote>
<p style="margin-left:0in;"><span style="color:#333333;">作用</span><span style="color:#333333;">：可以</span><span style="color:#ff0000;">使得</span><span style="color:#ff0000;">W</span><span style="color:#ff0000;">的每个元素都很小，都接近于</span><span style="color:#ff0000;">0</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">优点：</span><span style="color:#000000;">越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象</span></p>
</blockquote>

<h2 id="%E5%B8%A6%E6%9C%89%E6%AD%A3%E5%88%99%E5%8C%96%E7%9A%84%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92-Ridge" style="margin-left:0in;"><a name="t18"></a><span style="color:#7030a0;">带有正则化的线性回归</span><span style="color:#7030a0;">-Ridge</span></h2>
<blockquote>
<p>•<span style="color:#000000;">sklearn.linear_model.</span><span style="color:#ff0000;">Ridge</span></p>
</blockquote>

<h2 id="Ridge"><a name="t19"></a><span style="color:#e46c0a;">Ridge</span></h2>
<blockquote>
<p>•<span style="color:#000000;">sklearn.linear_model.Ridge(</span><span style="color:#000000;"><em>alpha=1.0</em></span><span style="color:#000000;">)</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">具有</span><span style="color:#000000;">l2</span><span style="color:#000000;">正则化的线性最小二乘法</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">alpha:</span><span style="color:#000000;">正则化力度</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">coef</span><span style="color:#000000;">_:</span><span style="color:#000000;">回归系数</span></p>
</blockquote>

<h2 id="%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%20LinearRegression%E4%B8%8ERidge%E5%AF%B9%E6%AF%94" style="margin-left:0in;"><a name="t20"></a><span style="color:#e46c0a;">线性回归</span> <span style="color:#e46c0a;">LinearRegression</span><span style="color:#e46c0a;">与</span><span style="color:#e46c0a;">Ridge</span><span style="color:#e46c0a;">对比</span></h2>
<blockquote>
<p>•<span style="color:#000000;">岭回归：回归得到的</span><span style="color:#ff0000;">回归系数更符合实际，更可靠</span><span style="color:#000000;">。另外，能让估计参数的波动范围变小，变的更稳定。在存在病态数据偏多的研究中有较大的实用价值。</span></p>
</blockquote>

<h2 id="sklearn%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E6%8C%81%E5%92%8C%E5%8A%A0%E8%BD%BD"><a name="t21"></a>sklearn模型的保持和加载</h2>
<p id="%C2%A0%E2%80%8B">&nbsp;<img alt="" class="has" height="31" src="https://img-blog.csdnimg.cn/20190722120558317.png" width="403"></p>
<h3 id="%E4%BF%9D%E5%AD%98%E5%92%8C%E5%8A%A0%E8%BD%BDAPI"><a name="t22"></a>保存和加载API</h3>
<p><img alt="" class="has" height="306" src="https://img-blog.csdnimg.cn/20190722120646746.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="362"></p>
<h1 id="4%E3%80%81%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92" style="margin-left:0in;"><a name="t23"></a><span style="color:#000000;">4</span><span style="color:#000000;">、分类算法</span><span style="color:#000000;">-</span><span style="color:#000000;">逻辑回归</span></h1>
<blockquote>
<p style="margin-left:0in;"><span style="color:#0070c0;">逻辑回归是解决二分类问题的利器</span></p>
</blockquote>

<h2 id="%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92" style="margin-left:0in;"><a name="t24"></a><span style="color:#7030a0;">逻辑回归</span></h2>
<p id="%E2%80%8B"><img alt="" class="has" height="78" src="https://img-blog.csdnimg.cn/20190722121136805.png" width="366"></p>
<h2 id="sigmoid%E5%87%BD%E6%95%B0" style="margin-left:0in;"><a name="t25"></a><span style="color:#e46c0a;">sigmoid</span><span style="color:#e46c0a;">函数</span></h2>
<p><img alt="" class="has" height="280" src="https://img-blog.csdnimg.cn/20190722121200156.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="409"></p>
<h2 id="%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E5%85%AC%E5%BC%8F"><a name="t26"></a><span style="color:#7030a0;">逻辑回归公式</span></h2>
<p><img alt="" class="has" height="258" src="https://img-blog.csdnimg.cn/20190722121218197.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="383"></p>
<h2 id="%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E3%80%81%E4%BC%98%E5%8C%96(%E4%BA%86%E8%A7%A3)"><a name="t27"></a><span style="color:#7030a0;">逻辑回归的损失函数、优化</span><span style="color:#7030a0;">(</span><span style="color:#7030a0;">了解</span><span style="color:#7030a0;">)</span></h2>
<p><img alt="" class="has" height="365" src="https://img-blog.csdnimg.cn/20190722121234730.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="592"></p>
<p><img alt="" class="has" height="294" src="https://img-blog.csdnimg.cn/20190722121625324.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="396">&nbsp;&nbsp;<img alt="" class="has" height="293" src="https://img-blog.csdnimg.cn/20190722121636140.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="398"></p>
<h2 id="sklearn%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92API" style="margin-left:0in;"><a name="t28"></a><span style="color:#7030a0;">sklearn</span><span style="color:#7030a0;">逻辑回归</span><span style="color:#7030a0;">API</span></h2>
<blockquote>
<p>•<span style="color:#000000;">sklearn.linear_model.LogisticRegression</span></p>
</blockquote>

<h2 id="LogisticRegression"><a name="t29"></a><span style="color:#e46c0a;">LogisticRegression</span></h2>
<blockquote>
<p>•<span style="color:#000000;">sklearn.linear_model.LogisticRegression</span><span style="color:#222222;">(</span><span style="color:#000000;"><em>penalty=‘l2’,</em></span><span style="color:#000000;"><em> C = 1.0</em></span><span style="color:#222222;">)</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">Logistic</span><span style="color:#000000;">回归分类器</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">coef_</span><span style="color:#000000;">：回归系数</span></p>
</blockquote>

<h2 id="LogisticRegression%E6%80%BB%E7%BB%93" style="margin-left:0in;"><a name="t30"></a><span style="color:#7030a0;">LogisticRegression</span><span style="color:#7030a0;">总结</span></h2>
<blockquote>
<p style="margin-left:0in;"><span style="color:#000000;">应用：广告点击率预测、电商购物搭配推荐</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">优点：</span><span style="color:#000000;">适合需要得到一个分类概率的场景</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">缺点：</span><span style="color:#000000;">当特征空间很大时，逻辑回归的性能不是很好</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">（看硬件能力）</span></p>
</blockquote>

<h1 id="5%E3%80%81%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95-kmeans" style="margin-left:0in;"><a name="t31"></a><span style="color:#000000;">5、聚类算法</span><span style="color:#000000;">-</span><span style="color:#000000;">kmeans</span></h1>
<h2 id="%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0(unsupervised%20learning)" style="margin-left:0in;"><a name="t32"></a><span style="color:#0070c0;">非监督学习</span><span style="color:#0070c0;">(unsupervised learning)</span></h2>
<p><span style="color:#000000;">主要方法：</span><span style="color:#000000;">k-means</span></p>
<h2 id="k-means%E6%AD%A5%E9%AA%A4"><a name="t33"></a><span style="color:#7030a0;">k-means</span><span style="color:#7030a0;">步骤</span></h2>
<p><img alt="" class="has" height="628" src="https://img-blog.csdnimg.cn/2019072414454014.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="909"></p>
<h2 id="k-means%20API" style="margin-left:0in;"><a name="t34"></a><span style="color:#7030a0;">k-means API</span></h2>
<blockquote>
<p>•<span style="color:#000000;">sklearn.cluster.</span><span style="color:#FF0000;">KMeans</span></p>
</blockquote>

<h2 id="Kmeans" style="margin-left:0in;"><a name="t35"></a><span style="color:#e46c0a;">Kmeans</span></h2>
<blockquote>
<p>•<span style="color:#000000;">sklearn.cluster.KMeans(</span><span style="color:#000000;"><em>n_clusters=8,init=‘k-means++’</em></span><span style="color:#000000;">)</span></p>

<p style="text-indent:50px;">•<span style="color:#000000;">k-means</span><span style="color:#000000;">聚类</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">n_clusters</span><span style="color:#000000;">:</span><span style="color:#000000;">开始的聚类中心数量</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">init</span><span style="color:#000000;">:</span><span style="color:#000000;">初始化方法，默认为</span><span style="color:#000000;">'k-means ++’</span></p>
<p style="text-indent:50px;">•<span style="color:#000000;">labels_:</span><span style="color:#000000;">默认标记的类型，可以和真实值比较（不是值比较）</span></p>
</blockquote>

<h2 id="k-means%E5%AF%B9Instacart%20Market%E7%94%A8%E6%88%B7%E8%81%9A%E7%B1%BB"><a name="t36"></a><span style="color:#e46c0a;">k-means</span><span style="color:#e46c0a;">对</span><span style="color:#e46c0a;">Instacart</span> <span style="color:#e46c0a;">Market</span><span style="color:#e46c0a;">用户聚类</span></h2>
<blockquote>
<p><span style="color:#000000;">1、降维之后的数据</span></p>

<p style="margin-left:0in;"><span style="color:#000000;">2</span><span style="color:#000000;">、</span><span style="color:#000000;">k-means</span><span style="color:#000000;">聚类</span></p>
<p style="margin-left:0in;"><span style="color:#000000;">3</span><span style="color:#000000;">、聚类结果显示</span></p>
</blockquote>

<h2 id="Kmeans%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87" style="margin-left:0in;"><a name="t37"></a><span style="color:#e46c0a;">Kmeans</span><span style="color:#e46c0a;">性能评估指标</span></h2>
<p><img alt="" class="has" height="304" src="https://img-blog.csdnimg.cn/2019072414481019.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2OTEwNjM0,size_16,color_FFFFFF,t_70" width="683"></p>
